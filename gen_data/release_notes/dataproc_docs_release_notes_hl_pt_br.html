<article class="devsite-article">
 <article class="devsite-article-inner">
  <devsite-toc class="devsite-nav" devsite-toc-embedded="">
  </devsite-toc>
  <div class="devsite-article-body clearfix devsite-no-page-title">
   <p>
    <meta name="project_path" value="/dataproc/docs/_project.yaml">
     <meta name="book_path" value="/dataproc/_book.yaml">
      <title>
       Notas da versão
      </title>
      <link href="https://cloud.google.com/feeds/cloud-dataproc-release-notes.xml?hl=pt_br" rel="alternate" type="application/atom+xml">
      </link>
     </meta>
    </meta>
   </p>
   <section class="intro">
    Estas notas da versão aplicam-se ao serviço Cloud Dataproc principal. Você pode consultar esta página periodicamente para ver anúncios sobre recursos novos ou atualizados, correções de bugs, problemas conhecidos e funcionalidades com uso suspenso.
    <p>
    </p>
    <p>
     Consulte a
     <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
      Lista das versões do Cloud Dataproc
     </a>
     para ver os componentes de software atuais e anteriores compatíveis com as imagens de software usadas nas máquinas virtuais do Cloud Dataproc.
    </p>
    <p>
     O Cloud Dataproc lança uma nova versão a cada semana, com uma janela de distribuição de quatro dias a partir de terça-feira.
    </p>
   </section>
   <section class="xml">
    <p>
     <a href="https://cloud.google.com/feeds/cloud-dataproc-release-notes.xml?hl=pt_br" track-metadata-position="introParagraph" track-name="xmlFeed" track-type="releaseNotes">
      Inscreva-se nas notas da versão do Cloud Dataproc.
      <img alt="Inscrever-se" src="https://cloud.google.com/images/feed-icon.png?hl=pt_br"/>
     </a>
    </p>
   </section>
   <section class="releases">
    <aside class="note">
     <strong>
      Lançamentos em etapas
     </strong>
     : as versões do Cloud Dataproc ocorrem em etapas ao longo de quatro dias. Publicamos essas notas da versão no primeiro dia do lançamento.
    </aside>
    <h2 data-text="Observações importantes sobre atualização cruzada" id="important_cross-update_notes">
     Observações importantes sobre atualização cruzada
    </h2>
    <div class="release-issue">
     <strong>
      ISSUE:
     </strong>
     <ul>
      <li>
       No futuro, o Cloud Dataproc será migrado de diversos repositórios do GitHub para o material do Cloud Dataproc, como
       <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/">
        ações de inicialização
       </a>
       e
       <a href="https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/dataproc">
        documentação
       </a>
       neste
       <a href="https://github.com/GoogleCloudPlatform/cloud-dataproc">
        repositório consolidado
       </a>
       . Isso facilitará a localização de todos os materiais relacionados ao Cloud Dataproc no GitHub. Durante a migração e por um período depois dela, o conteúdo ficará disponível nos dois locais.
      </li>
      <li>
       A partir de 04/01/2019, o
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        Cloud Dataproc 1.3
       </a>
       será a versão padrão para novos clusters.
      </li>
     </ul>
    </div>
    <h2 data-text="4 de dezembro de 2018" id="december_4_2018">
     4 de dezembro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        Beta
       </a>
       de
       <a href="https://cloud.google.com/dataproc/docs/reference/rest/v1beta2/projects.regions.jobs?hl=pt_br#SparkRJob">
        jobs do SparkR no Cloud Dataproc
       </a>
       .
Esse recurso permite enviar jobs do
       <a class="external" href="https://spark.apache.org/docs/latest/sparkr.html">
        SparkR
       </a>
       em um cluster do Cloud Dataproc usando a ferramenta de linha de comando
       <code>
        gcloud
       </code>
       , o Console do Google Cloud Platform ou a API Cloud Dataproc.
      </li>
      <li>
       Anúncio da versão de
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        Disponibilidade geral (GA, na sigla em inglês)
       </a>
       de
       <a href="https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-local-ssds?hl=pt_br">
        SSDs locais do Cloud Dataproc em trabalhos preemptivos
       </a>
       .
       <a href="https://cloud.google.com/compute/docs/disks/local-ssd?hl=pt_br">
        SSDs locais
       </a>
       já podem ser adicionados a nós de trabalho preemptivos (secundários) em um cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="16 de novembro de 2018" id="november_16_2018">
     16 de novembro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        Beta
       </a>
       do
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/optional-components?hl=pt_br#presto">
        Cloud Dataproc: componente de nível superior Presto
       </a>
       .
    Esse recurso permite que os usuários instalem o
       <a class="external" href="https://prestodb.io">
        Presto
       </a>
       ao criar novos clusters do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.102-deb9, 1.1.93-deb9, 1.2.56-deb9,
      1.3.16-deb9
       </code>
       .
      </li>
      <li>
       A criação de clusters do Dataproc agora emitirá um aviso se detectarmos uma vulnerabilidade de segurança em potencial por causa de regras de firewall configuradas incorretamente, permitindo acesso público a portas YARN.
      </li>
      <li>
       A pesquisa dos detalhes de um job mostrará quem enviou esse job no campo submittedBy.
      </li>
      <li>
       Somente imagem 1.3:
       <ul>
        <li>
         Upgrade do Conector do Cloud Storage para a versão 1.9.10. Consulte as
         <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.10">
          notas da versão do GitHub
         </a>
         .
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <h2 data-text="12 de novembro de 2018" id="november_12_2018">
     12 de novembro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.101-deb9, 1.1.92-deb9, 1.2.55-deb9,
      1.3.15-deb9
       </code>
       .
      </li>
      <li>
       As versões de imagem secundárias agora redirecionam para imagens baseadas no Debian 9.
    Por exemplo, 1.2 agora aponta para 1.2-deb9. Não haverá novas imagens baseadas no Debian 8.
      </li>
      <li>
       Os UUIDs de job agora são expostos para permitir que as execuções de job sejam identificadas de maneira exclusiva.
      </li>
      <li>
       O conector do Cloud Storage agora define
       <code>
        fadvise
       </code>
       como
       <code>
        SEQUENTIAL
       </code>
       para jobs do Hadoop DistCp. Esse modo é otimizado para leituras de streaming, que são mais eficientes para essas cargas de trabalho.
      </li>
      <li>
       Remoção do jar de inicialização ALPN de versões do Cloud Dataproc 1.0 e 1.1 por causa da incompatibilidade com o OpenJDK 8 mais recente distribuído com o Debian. Os usuários do gRPC precisam usar uma forma de
       <code>
        netty-tcnative
       </code>
       . Por exemplo,
       <code>
        io.grpc:grpc-netty-shaded
       </code>
       . Isso já se aplica a 1.2 e 1.3.
      </li>
      <li>
       Redução da prioridade do processo Linux de jobs do usuário.
      </li>
      <li>
       <code>
        dfs.namenode.datanode.registration.retry-hostname-dns-lookup
       </code>
       já está definido como
       <code>
        true
       </code>
       .
      </li>
      <li>
       Aumento do número máximo de tarefas DistCp programadas por nó. Isso melhora o desempenho de DistCp.
      </li>
      <li>
       Somente imagem 1.3:
       <ul>
        <li>
         Portação de
         <a class="external" href="https://issues.apache.org/jira/browse/HDFS-13056">
          HDFS-13056
         </a>
         para Hadoop 2.9.
        </li>
        <li>
         Upgrade do Conector do Cloud Storage para a versão 1.9.9. Consulte as
         <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.9">
          notas da versão do GitHub
         </a>
         .
        </li>
        <li>
         O Presto já é compatível como um componente de nível superior opcional.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um bug em que o CMEK não foi passado para PD em trabalhos preemptivos.
      </li>
      <li>
       Correção de um bug em que alterações feitas em
       <code>
        PATH
       </code>
       em imagens personalizadas interrompiam a inicialização do Cloud Dataproc. Por exemplo, alterar o Python padrão para o Python 3 interrompia a inicialização.
      </li>
      <li>
       Correção de um bug em que solicitações POST e PUT para a API REST YARN eram bloqueadas por usuários anônimos no Cloud Dataproc 1.3. Isso foi corrigido com adição de
       <code>
        org.apache.hadoop.http.lib.StaticUserWebFilter
       </code>
       de volta para
       <code>
        hadoop.http.filter.initializers
       </code>
       em
       <code>
        core-site.xml
       </code>
      </li>
      <li>
       Correção de avisos do registro em log no Hive 2 no Cloud Dataproc 1.1, 1.2 e 1.3.
      </li>
     </ul>
    </div>
    <h2 data-text="2 de novembro de 2018" id="november_2_2018">
     2 de novembro de 2018
    </h2>
    <div class="release-issue">
     <strong>
      ISSUE:
     </strong>
     <p>
      Desde 2 de novembro de 2018, o Cloud Dataproc parou de lançar imagens baseadas no Debian 8.
As versões 1.X depois de 2 de novembro de 2018 usarão o Debian 9 como o SO base delas.
Não serão lançadas atualizações adicionais, patches ou correções de segurança para o Debian 8 depois 2 de novembro de 2018.
     </p>
    </div>
    <div class="release-issue">
     <strong>
      ISSUE:
     </strong>
     <p>
      Em 9 de novembro de 2018, o jar de inicialização ALPN será removido do caminho de classe de imagens futuras do Cloud Datproc versão 1.0 e 1.1 por causa de incompatibilidades com os patches de segurança mais recentes do pacote do Debian OpenJDK 8. As versões 1.2 e 1.3 da imagem serão clientes Java gRPC e precisarão usar
      <a class="external" href="https://github.com/grpc/grpc-java/blob/master/SECURITY.md#tls-with-openssl">
       netty-tcnative
      </a>
      na autenticação com APIs do Google. Os clientes, como o Cloud Bigtable que agrupam netty-tcnative podem depender de
      <a class="external" href="https://search.maven.org/artifact/io.grpc/grpc-netty-shaded/1.16.1/jar">
       grpc-netty-shaded
      </a>
      para evitar colisões com o Hadoop Classpath. Consulte
      <a href="https://cloud.google.com/dataproc/docs/guides/manage-spark-dependencies?hl=pt_br">
       Gerenciar dependências Java e Scala do Apache Spark
      </a>
      para saber mais informações.
     </p>
    </div>
    <h2 data-text="26 de outubro de 2018" id="october_26_2018">
     26 de outubro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.100-deb8, 1.1.91-deb8, 1.2.54-deb8,
    1.3.14-deb8, 1.0.100-deb9, 1.1.91-deb9, 1.2.54-deb9, 1.3.14-deb9
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema de
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/scaling-clusters?hl=pt_br#graceful_decommissioning_and_secondary_workers">
        Desativação otimizada e funcionários secundários
       </a>
       . Durante o uso da desativação otimizada para remover trabalhos secundários (preemptivos) logo após o escalonamento do grupo de trabalhos secundários, um erro ocorreria com uma mensagem de erro semelhante à seguinte: "O grupo de trabalhos secundários não pode ser modificado fora do Cloud Dataproc. Se você tiver criado ou atualizado este cluster recentemente, espere alguns minutos antes da desativação otimizada para permitir que todas as instâncias secundárias participem do cluster ou saiam dele. Tamanho do grupo de trabalhos secundário esperado: x, tamanho real: y."
       <br/>
       <strong>
        Informações relacionadas:
       </strong>
       <ul>
        <li>
         O Cloud Dataproc chama
         <code>
          listManagedInstances
         </code>
         no grupo de instâncias gerenciadas que administra trabalhos secundários, filtra instâncias com ação atual EXCLUSÃO ou ABANDONO e escolhe as instâncias a serem excluídas do grupo resultante. O Cloud Dataproc prefere excluir VMs que estejam sendo criadas, em vez de executar VMs.
        </li>
        <li>
         Durante a descrição de um cluster, o grupo de trabalhos secundário continuará sendo exibido para que tenham instâncias EXCLUSÃO e ABANDONO. Por isso, o tamanho de destino do grupo talvez não corresponda ao tamanho da lista de nomes do host, mesmo após a conclusão da operação do escalonamento. As instâncias serão removidas da lista quando forem excluídas do grupo de instâncias gerenciadas.
        </li>
       </ul>
      </li>
      <li>
       Correção de problemas que levavam a um "erro interno do servidor" durante a criação de clusters.
      </li>
     </ul>
    </div>
    <h2 data-text="22 de outubro de 2018" id="october_22_2018">
     22 de outubro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       O Cloud Dataproc já está disponível na
       <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
        região
       </a>
       <code>
        asia-east2
       </code>
       (Hong Kong).
      </li>
     </ul>
    </div>
    <h2 data-text="19 de outubro de 2018" id="october_19_2018">
     19 de outubro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.99-deb8, 1.1.90-deb8, 1.2.53-deb8, 1.3.13-deb8,
    1.0.99-deb9, 1.1.90-deb9, 1.2.53-deb9, 1.3.13-deb9
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Somente imagem 1.0: correção de um bug em que as métricas do Stackdriver não estavam sendo publicadas, o que também afetava a funcionalidade de escalonamento automático.
      </li>
     </ul>
    </div>
    <h2 data-text="12 de outubro de 2018" id="october_12_2018">
     12 de outubro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.98-deb8, 1.1.89-deb8, 1.2.52-deb8, 1.3.12-deb8,
    1.0.98-deb9, 1.1.89-deb9, 1.2.52-deb9, 1.3.12-deb9
       </code>
       .
      </li>
      <li>
       Somente imagem 1.3: upgrade do conector do Cloud Storage. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.8">
        observações de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.9.8.
        </li>
       </ul>
      </li>
      <li>
       Somente imagem 1.0: upgrade do Hadoop para 2.7.4.
      </li>
     </ul>
    </div>
    <h2 data-text="9 de outubro de 2018" id="october_9_2018">
     9 de outubro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        General Availability (GA)
       </a>
       de
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption?hl=pt_br">
        Chaves de criptografia gerenciadas pelo cliente do Cloud Dataproc no Compute Engine
       </a>
       .
Esse recurso permite criar, usar e revogar a
       <a href="https://cloud.google.com/security/encryption-at-rest?hl=pt_br">
        Key Encryption Key (KEK)
       </a>
       em discos permanentes (PDs, na sigla em inglês) associados a VMs do Compute Engine no cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="5 de outubro de 2018" id="october_5_2018">
     5 de outubro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.97-deb8, 1.1.88-deb8, 1.2.51-deb8, 1.3.11-deb8,
    1.0.97-deb9, 1.1.88-deb9, 1.2.51-deb9, 1.3.11-deb9
       </code>
       .
      </li>
      <li>
       Somente imagem 1.1: upgrade do Zeppelin para 0.7.3.
      </li>
      <li>
       Somente imagem 1.1: publicação das métricas YARN e HDFS para o Stackdriver, exceto PendingDeletionBlocks HDFS, de clusters usando a versão da imagem 1.1.82 e posteriores.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema em que o tempo limite da primeira ação de inicialização era usado como o tempo limite em todas as outras ações de inicialização.
      </li>
      <li>
       Correção do problema incomum em que a criação do cluster falhou com o erro
       <code>
        debconf: DbDriver "config": /var/cache/debconf/config.dat is
    locked by another process: Resource temporarily unavailable
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="28 de setembro de 2018" id="september_28_2018">
     28 de setembro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Recurso (1.2+): ativação da nova
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/cluster-properties?hl=pt_br">
        propriedade de cluster
       </a>
       <code>
        dataproc:am.primary_only
       </code>
       para evitar a execução do mestre do aplicativo em trabalhos preemptivos.
    Esse recurso só é ativado para clusters do Dataproc 1.2+.
    Para usar a propriedade do cluster, defina
       <code>
        --properties dataproc:am.primary_only=true
       </code>
       ao criar um cluster.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.97-deb8, 1.1.88-deb8, 1.2.51-deb8, 1.3.11-deb8,
    1.0.97-deb9, 1.1.88-deb9, 1.2.51-deb9, 1.3.11-deb9
       </code>
       .
      </li>
      <li>
       Somente imagem 1.3: upgrade do conector do Cloud Storage. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.7">
        observações de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.9.7.
        </li>
       </ul>
      </li>
      <li>
       Somente imagem 1.0-1.2: upgrades dos conectores do Cloud Storage e do BigQuery. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.10">
        observações de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.6.10.
        </li>
        <li>
         O conector do BigQuery foi atualizado para a versão 0.10.11.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção do problema em que o servidor de histórico do Spark falhava na inicialização.
      </li>
      <li>
       Correção do problema em que o escalonamento automático para após 1.000 períodos de refrigeração.
      </li>
     </ul>
    </div>
    <h2 data-text="25 de setembro de 2018" id="september_25_2018">
     25 de setembro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        General Availability (GA)
       </a>
       de
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=pt_br">
        Modelos do fluxo de trabalho do Cloud Dataproc
       </a>
       , inclusive
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/workflow-parameters?hl=pt_br">
        Parametrização do modelo do fluxo de trabalho
       </a>
       e a
       <a href="https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/instantiateInline?hl=pt_br">
        API Workflow Templates InstantiateInline
       </a>
       .
      </li>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        General Availability (GA)
       </a>
       do
       <a href="https://cloud.google.com/dataproc/docs/concepts/iam/granular-iam?hl=pt_br">
        IAM granular do Cloud Dataproc
       </a>
       .
Esse recurso permite definir papéis do IAM e as permissões correspondentes deles por cluster.
      </li>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        Beta
       </a>
       de
       <a href="https://cloud.google.com/dataproc/docs/guides/create-cluster?hl=pt_br#creating_a_dataproc_name_short_cluster">
        Importação/exportação do cluster de YAML
       </a>
       do Cloud Dataproc.
Este recurso permite usar a ferramenta de linha de comando gcloud para exportar a configuração de um cluster do Cloud Dataproc atual para um arquivo YAML e criar um novo cluster importando a configuração do arquivo YAML.
      </li>
      <li>
       Anúncio da versão
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        Beta
       </a>
       de
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/optional-components?hl=pt_br">
        Componentes opcionais
       </a>
       do Cloud Dataproc.
    Com esse recurso, é possível especificar outros componentes para a instalação durante a criação de novos clusters do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <h2 data-text="21 de setembro de 2018" id="september_21_2018">
     21 de setembro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da ação de inicialização
       <a class="external" href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/blob/master/beam/">
        Beam on Flink on Dataproc
       </a>
       (
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        Beta
       </a>
       ) no GitHub, que configura o serviço Apache Beam em um cluster do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <p>
    </p>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.95-deb8, 1.1.86-deb8, 1.2.49-deb8, 1.3.9-deb8,
    1.0.95-deb9, 1.1.86-deb9, 1.2.49-deb9, 1.3.9-deb9
       </code>
       .
      </li>
      <li>
       Alteração das ações de inicialização a serem executadas dentro de um shell de login. Dessa maneira, as alterações feitas no perfil do ambiente podem ser vistas por ações init subsequentes.
      </li>
      <li>
       Somente imagem 1.3: upgrade do conector do Cloud Storage. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.6">
        observações de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.9.6.
        </li>
       </ul>
      </li>
      <li>
       Somente imagem 1.0-1.2: upgrades dos conectores do Cloud Storage e do BigQuery. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.9">
        observações de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.6.9.
        </li>
        <li>
         O conector do BigQuery foi atualizado para a versão 0.10.10.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <p>
    </p>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção do problema em que os clientes baseados em gRPC podem falhar durante a chamada Receber/listar em operações após o uso da API v1beta2 para realizar operações de cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="14 de setembro de 2018" id="september_14_2018">
     14 de setembro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.94-deb8, 1.1.85-deb8, 1.2.48-deb8, 1.3.8-deb8,
    1.0.94-deb9, 1.1.85-deb9, 1.2.48-deb9, 1.3.8-deb9
       </code>
       .
      </li>
      <li>
       Adição de
       <code>
        Flink 1.5.0
       </code>
       e
       <code>
        HBase 1.3.2
       </code>
       a imagens
       <code>
        1.3-deb8
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Aprimoramento de granularidade e precisão das métricas do Hadoop.
      </li>
      <li>
       Correção do problema de falha do serviço Hue ao iniciar em imagens
       <code>
        1.3-deb9
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="31 de agosto de 2018" id="august_31_2018">
     31 de agosto de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.93-deb8, 1.1.84-deb8, 1.2.47-deb8, 1.3.7-deb8,
    1.0.93-deb9, 1.1.84-deb9, 1.2.47-deb9, 1.3.7-deb9
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção do problema que impedia trabalhos de ingressar no cluster durante o uso da
       <a class="external" href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/connectors">
        ação init de conectores
       </a>
       .
      </li>
      <li>
       Correção do problema que provocava a falha dos jobs do Hive quando enviados durante o primeiro minuto após a criação do cluster.
      </li>
      <li>
       Correção do mau funcionamento das ações de inicialização por causa do erro
       <code>
        E: Could not get lock
    /var/lib/dpkg/lock
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="30 de agosto de 2018" id="august_30_2018">
     30 de agosto de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da versão de
       <a href="https://cloud.google.com/terms/launch-stages?hl=pt_br#launch-stages">
        disponibilidade geral (GA, na sigla em inglês)
       </a>
       das
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption?hl=pt_br">
        chaves de criptografia gerenciadas pelo cliente do Cloud Dataproc no Cloud Storage
       </a>
       .
Esse recurso permite criar, usar e revogar a
       <a href="https://cloud.google.com/security/encryption-at-rest?hl=pt_br">
        chave de criptografia de chaves (KEK, na sigla em inglês)
       </a>
       no intervalo do Cloud Storage usado pelo Cloud Dataproc para gravar metadados de cluster e a saída do driver do job.
      </li>
     </ul>
    </div>
    <h2 data-text="24 de agosto de 2018" id="august_24_2018">
     24 de agosto de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.92-deb8, 1.1.83-deb8, 1.2.46-deb8, 1.3.6-deb8,
    1.0.92-deb9, 1.1.83-deb9, 1.2.46-deb9, 1.3.6-deb9
       </code>
       .
      </li>
      <li>
       Somente imagem 1.0-1.2: upgrades dos conectores do Cloud Storage e do BigQuery. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.8">
        observações de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.6.8.
        </li>
        <li>
         O conector do BigQuery foi atualizado para a versão 0.10.9.
        </li>
       </ul>
      </li>
      <li>
       Somente imagem 1.3: upgrade do conector do Cloud Storage para a versão 1.9.5. Para saber mais informações, consulte
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.5">
        observações de alteração
       </a>
       no repositório do GitHub.
      </li>
      <li>
       Imagem 1.3 apenas com o Debian 9:
       <ul>
        <li>
         Atualize o Spark para 2.3.1.
        </li>
        <li>
         Adicione o HBase 1.3.2.
        </li>
        <li>
         Adicione o Flink 1.5.0.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção do
       <a class="external" href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/pull/313">
        problema
       </a>
       no Dataproc imagem versão 1.2, em que JARs ASM conflitantes podem causar uma falha no Zeppelin.
      </li>
      <li>
       Correção do problema no Dataproc imagem versão 1.3, em que a compressão do Snappy no formato de arquivo ORC no Spark foi interrompida. Essa foi uma regressão introduzida na imagem versão 1.3.3, enquanto resolvia o
       <a class="external" href="https://issues.apache.org/jira/browse/SPARK-24018">
        SPARK-24018
       </a>
       .
    Após essa correção, o Parquet e o ORC podem usar a compressão do Snappy.
      </li>
     </ul>
    </div>
    <h2 data-text="16 de agosto de 2018" id="august_16_2018">
     16 de agosto de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Há novas imagens baseadas no Debian 9 para as versões de imagens 1.0-1.3. Elas podem ser acessadas anexando '-deb9" às faixas de versão existentes (por exemplo, 1.2-deb9).
      </li>
      <li>
       Até 2 de novembro de 2018, as versões de imagens 1.X atuais usarão imagens do Debian 8 (por exemplo, 1.3 será resolvido para 1.3.Y-deb8).
    Em 2 de novembro de 2018, as versões de imagens 1.X mudarão para imagens do Debian 9. O Debian 8 não será usado em novas versões de imagens a partir de 2 de novembro de 2018.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.91-deb8, 1.0.91-deb9, 1.1.82-deb8, 1.1.82-deb9, 1.2.45-deb8, 1.2.45-deb9, 1.3.5-deb8, 1.3.5-deb9
       </code>
       .
      </li>
      <li>
       Correção de segurança: instale o Linux Kernel 4.9 em todas as versões de imagens para receber correções de segurança para
       <a href="https://security-tracker.debian.org/tracker/CVE-2018-3590">
        CVE-2018-3590
       </a>
       e
       <a href="https://security-tracker.debian.org/tracker/CVE-2018-3591">
        CVE-2018-3591
       </a>
       em todas as novas imagens do Debian 8.
      </li>
     </ul>
    </div>
    <h2 data-text="10 de agosto de 2018" id="august_10_2018">
     10 de agosto de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.90, 1.1.81, 1.2.45, 1.3.5
       </code>
       .
      </li>
      <li>
       Definição do número máximo de arquivos abertos como 65535 para todos os serviços Systemd.
      </li>
     </ul>
    </div>
    <h2 data-text="3 de agosto de 2018" id="august_3_2018">
     3 de agosto de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.89, 1.1.80, 1.2.44, 1.3.4
       </code>
       .
      </li>
      <li>
       Nos clusters de alta disponibilidade (HA, na sigla em inglês),
       <code>
        hadoop.security.token.service.use_ip
       </code>
       está agora definido como "false".
      </li>
      <li>
       Atualização do Hadoop para 2.8.4. (Dataproc 1.2)
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção do problema de falha em que jobs do Hive falhariam em clusters 1.3 HA
      </li>
      <li>
       Correção do valor padrão de
       <code>
        mapreduce.jobhistory.recovery.store.fs.uri
       </code>
       com a definição novamente como
       <code>
        ${hadoop.tmp.dir}/mapred/history/recoverystore
       </code>
       . Ele havia sido configurado por engano para
       <code>
        hdfs:///mapred/history/recoverystore
       </code>
       na versão de 6 de julho.
      </li>
      <li>
       Backports de
       <a class="external" href="https://issues.apache.org/jira/browse/ZOOKEEPER-1576">
        ZOOKEEPER -1576
       </a>
       no ZooKeeper 3.4.6 no Dataproc 1.2 e 1.3.
    Esse bug causava falha nas conexões do Zookeper caso algum dos servidores falhasse na resolução.
      </li>
     </ul>
    </div>
    <h2 data-text="31 de julho de 2018" id="july_31_2018">
     31 de julho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio de
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/autoscaling?hl=pt_br">
        Escalonamento automático do Cloud Dataproc
       </a>
       (Alfa público). Esse recurso redimensiona automaticamente os clusters para atender às demandas de cargas de trabalho.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.3.3
       </code>
       .
      </li>
      <li>
       Houve alterações apenas na imagem do 1.3:
       <div class="release-changed">
        <strong>
         CHANGED:
        </strong>
        <ul>
         <li>
          Desativação da adição de nós à lista negra em jobs do Tez (conjunto
          <code>
           tez.am.node-blacklisting.enabled=false
          </code>
          ). Isso afeta todos os jobs do Hive, que são executados no Tez por padrão.
         </li>
        </ul>
       </div>
       <div class="release-fixed">
        <strong>
         FIXED:
        </strong>
        <ul>
         <li>
          Correção do problema de quebra de compactação nativa do Snappy nativa no spark-shell (
          <a class="external" href="https://issues.apache.org/jira/browse/SPARK-24018">
           SPARK-24018
          </a>
          ) e no
          <a class="external" href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/issues/289">
           Zeppelin
          </a>
          .
         </li>
         <li>
          Correção do problema que impedia que gsutil e gcloud funcionassem em VMs de cluster quando o componente opcional ANACONDA era selecionado.
         </li>
        </ul>
       </div>
      </li>
     </ul>
    </div>
    <h2 data-text="18 de julho de 2018" id="july_18_2018">
     18 de julho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anunciamos o recurso
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/workflow-parameters?hl=pt_br">
        parâmetros de fluxo de trabalho do Cloud Dataproc
       </a>
       (Beta). Com esse recurso, é possível reutilizar os modelos de fluxo de trabalho do Cloud Dataproc diversas vezes com parâmetros diferentes. Como parte do lançamento desse recurso, os usuários podem
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=pt_br#using_workflow_template_yaml_files">
        importar e exportar modelos de fluxo de trabalho diretamente de arquivos YAML
       </a>
       usando a ferramenta de linha de comando
       <code>
        gcloud
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="13 de julho de 2018" id="july_13_2018">
     13 de julho de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.88, 1.1.79, 1.2.43, 1.3.2
       </code>
       .
      </li>
      <li>
       Com o Cloud Dataproc, agora o local de recursos é adicionado aos registros de auditoria gerados na nuvem.
      </li>
     </ul>
    </div>
    <h2 data-text="10 de julho de 2018" id="july_10_2018">
     10 de julho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       O Cloud Dataproc agora está disponível na
       <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
        região
       </a>
       <code>
        us-west2
       </code>
       (Los Angeles).
      </li>
     </ul>
    </div>
    <h2 data-text="6 de julho de 2018" id="july_6_2018">
     6 de julho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anunciamos a versão alfa dos
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/optional-components?hl=pt_br">
        componentes opcionais
       </a>
       do Cloud Dataproc.
    Com esse recurso, é possível especificar outros componentes para a instalação ao criar novos clusters do Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.87, 1.1.78, 1.2.42, 1.3.1
       </code>
       .
      </li>
      <li>
       Houve alterações apenas na imagem do 1.3:
       <ul>
        <li>
         A IU da Web Spark por driver foi reativada.
        </li>
        <li>
         A biblioteca do HCatalog é instalada por padrão.
        </li>
       </ul>
      </li>
      <li>
       A recuperação do servidor do histórico de jobs do MapReduce agora está ativada por padrão.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Uma condição de corrida na criação do cluster de alta disponibilidade com o utilitário resolveip foi resolvida.
      </li>
     </ul>
    </div>
    <h2 data-text="29 de junho de 2018" id="june_29_2018">
     29 de junho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Cloud Dataproc 1.3: uma nova versão da imagem do Cloud Dataproc já está disponível.
       <ul>
        <li>
         A versão 1.3 da imagem passará a ser a versão de imagem padrão para novos clusters a partir de 30/07/2018. Consulte a
         <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
          lista de versões do Cloud Dataproc
         </a>
         para mais informações.
        </li>
       </ul>
       A versão 1.3 da imagem inclui as seguintes alterações:
       <ul>
        <li>
         O Apache Spark foi atualizado para a versão 2.3.0.
        </li>
        <li>
         O Apache Hadoop foi atualizado para a versão 2.9.0.
        </li>
        <li>
         O Apache Hive foi atualizado para a versão 2.3.2.
        </li>
        <li>
         O Hive é executado no Apache Tez por padrão.
        </li>
        <li>
         O
         <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/TimelineServer.html">
          YARN Timeline Server
         </a>
         está ativado por padrão.
        </li>
       </ul>
      </li>
      <li>
       Anunciamos a versão de disponibilidade geral (GA, na sigla em inglês) das
       <a href="https://cloud.google.com/dataproc/docs/guides/dataproc-images?hl=pt_br">
        imagens personalizadas
       </a>
       do Cloud Dataproc, anteriormente Beta. Com esse recurso, os usuários criam e salvam imagens personalizadas com pacotes pré-instalados. As imagens personalizadas são usadas para criar clusters do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.86, 1.1.77, 1.2.41, 1.3.0
       </code>
       .
      </li>
      <li>
       Houve alterações apenas na imagem do 1.3:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.9.0. Consulte as
         <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.9.0">
          notas de alteração
         </a>
         no repositório do GitHub.
        </li>
        <li>
         O servidor Kernel NFS não está mais instalado.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <h2 data-text="27 de junho de 2018" id="june_27_2018">
     27 de junho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Anúncio da versão Beta das
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption?hl=pt_br">
        chaves de criptografia gerenciadas pelo cliente (CMEK, na sigla em inglês) do Cloud Dataproc
       </a>
       , um recurso que permite usar e revogar a
       <a href="https://cloud.google.com/security/encryption-at-rest/default-encryption?hl=pt_br#key_management">
        chave de criptografia de chaves (KEK, na sigla em inglês)
       </a>
       para VMs do Compute Engine no cluster e para o intervalo do Cloud Storage usado com o Cloud Dataproc.
      </li>
      <li>
       Anúncio da disponibilização geral (GA) do Cloud Dataproc e das chaves de criptografia gerenciadas pelo cliente no BigQuery.
    Os usuários do Cloud Dataproc já podem usar
       <a href="https://cloud.google.com/bigquery/docs/customer-managed-encryption?hl=pt_br">
        chaves de criptografia gerenciadas pelo cliente (CMEK, na sigla em inglês)
       </a>
       para acesso a conjuntos de dados e tabelas protegidos do BigQuery. Consulte
       <a href="https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-mapreduce-example?hl=pt_br">
        Como gravar um job do MapReduce com o conector do BigQuery
       </a>
       para ver um exemplo.
      </li>
      <li>
       Anunciamos a versão de disponibilidade geral (GA) dos
       <a href="https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-pd-ssd?hl=pt_br">
        discos permanentes de inicialização da unidade de estado sólido (PD-SSD, na sigla em inglês) do Cloud Dataproc
       </a>
       . Com eles, é possível criar clusters que usam os PD-SSDs nos discos de inicialização dos nós mestres e de trabalho.
      </li>
     </ul>
    </div>
    <h2 data-text="22 de junho de 2018" id="june_22_2018">
     22 de junho de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.85, 1.1.76, 1.2.40
       </code>
       .
      </li>
      <li>
       Foram atualizados os conectores do Cloud Storage e do BigQuery em 1.0.85, 1.1.76 e 1.2.40. Para mais informações, revise as
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.7">
        notas de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.6.7.
        </li>
        <li>
         O conector do BigQuery foi atualizado para a versão 0.10.8.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <h2 data-text="15 de junho de 2018" id="june_15_2018">
     15 de junho de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.84, 1.1.75, 1.2.39
       </code>
       .
      </li>
      <li>
       A saída da "Ação de inicialização" atualmente está disponível no registro
       <code>
        google.dataproc.startup
       </code>
       do Stackdriver.
      </li>
      <li>
       Não será mais possível criar novos clusters no Cloud Dataproc com base na maioria das imagens criadas antes de 14/02/2018. Os clientes não precisam alterar as versões secundárias, mas caso especifiquem uma versão subsecundária adequada a esse grupo, precisarão de uma versão mais recente. Por exemplo, não é possível usar a 1.1.39 para novos clusters, mas a 1.1 e a 1.1.73 são válidas.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Foi corrigido o
       <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/issues/279">
        problema de ação de inicialização do ZooKeeper
       </a>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="11 de junho de 2018" id="june_11_2018">
     11 de junho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       O Cloud Dataproc atualmente está disponível na
       <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
        região
       </a>
       <code>
        europe-north1
       </code>
       (Finlândia).
      </li>
     </ul>
    </div>
    <h2 data-text="8 de junho de 2018" id="june_8_2018">
     8 de junho de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Google Cloud SDK 203.0.0, 29-05-2018
       <ul>
        <li>
         Veja a seguir algumas alterações realizadas:
         <ul>
          <li>
           Foi adicionado o
           <code>
            gcloud beta dataproc workflow-templates instantiate-from-file
           </code>
           para tornar possível a instanciação de modelos de fluxo de trabalho diretamente de um arquivo YAML.
          </li>
          <li>
           Foi adicionado o
           <code>
            gcloud beta dataproc clusters create-from-file
           </code>
           para tornar possível a criação de clusters diretamente de um arquivo YAML.
          </li>
         </ul>
        </li>
        <li>
         Consulte
         <a href="https://cloud.google.com/sdk/gcloud/reference/beta/dataproc/workflow-templates?hl=pt_br">
          a documentação de referência do Cloud SDK
         </a>
         para mais informações.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.83, 1.1.74, 1.2.38
       </code>
       .
      </li>
      <li>
       Altere a string de conexão do jdbc transmitida para o beeline ao enviar jobs do Hive para clusters de alta disponibilidade por meio da API Jobs do Cloud Dataproc. Essa nova string faz uso da alta disponibilidade do HiveServer2.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       O WorkflowTemplates passará a relatar corretamente as falhas do Job.
      </li>
     </ul>
    </div>
    <h2 data-text="28 de maio de 2018" id="may_28_2018">
     28 de maio de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.82, 1.1.73, 1.2.37
       </code>
       .
      </li>
      <li>
       O Hive Server 2 atualmente executa os três mestres no modo de alta disponibilidade.
      </li>
      <li>
       Houve alterações de imagens de visualização no Dataproc 1.3:
       <ul>
        <li>
         Agora é necessário um tamanho mínimo de disco de inicialização de 15 GB.
        </li>
        <li>
         A porta RPC do Serviço NameNode foi alterada de 8040 para 8051.
        </li>
        <li>
         A variável de ambiente
         <code>
          SPARK_HOME
         </code>
         agora está configurada de forma global.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       O jar de inicialização ALPN foi removido da 1.2. Esta regressão foi introduzida na 1.2.35.
      </li>
     </ul>
    </div>
    <h2 data-text="21 de maio de 2018" id="may_21_2018">
     21 de maio de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.81, 1.1.72, 1.2.36
       </code>
       .
      </li>
      <li>
       Foram realizados upgrades dos conectores do Cloud Storage e do BigQuery em 1.0.81, 1.1.72, 1.2.36. Para mais informações, revise as
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.6">
        notas de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.6.6.
        </li>
        <li>
         O conector do BigQuery foi atualizado para a versão 0.10.7.
        </li>
       </ul>
      </li>
      <li>
       Há uma nova versão da imagem de visualização do Cloud Dataproc 1.3:
       <ul>
        <li>
         Remover o conector do BigQuery da imagem. Os usuários precisam incluir o conector do BigQuery com jars nos respectivos jobs.
        </li>
        <li>
         O Cloud Dataproc 1.3 não é compatível.
        </li>
        <li>
         Consulte a
         <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#other_versions">
          lista de versões do Cloud Dataproc
         </a>
         para mais informações.
        </li>
       </ul>
      </li>
      <li>
       O Hive Metastore está configurado para execução nos três mestres em modo de alta disponibilidade.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Foi corrigido um problema em que a cota do acelerador era validada incorretamente. Por exemplo, poderia ocorrer uma falha na criação do cluster com um erro "Cota 'NVIDIA_K80_GPUS' insuficiente", mesmo que a cota fosse suficiente.
      </li>
     </ul>
    </div>
    <h2 data-text="14 de maio de 2018" id="may_14_2018">
     14 de maio de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Há um novo controle de imagens do Cloud Dataproc 1.3 disponível na visualização.
       <ul>
        <li>
         Veja a seguir algumas alterações realizadas:
         <ul>
          <li>
           Spark 2.3, Hadoop 2.9, Hive 2.3, Pig 0.17, Tez 0.9.
          </li>
          <li>
           Hive no Tez por padrão. A ação de inicialização do Tez não é necessária.
          </li>
         </ul>
        </li>
        <li>
         O Cloud Dataproc 1.3 não é oficialmente compatível.
        </li>
        <li>
         Consulte a
         <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#other_versions">
          lista de versões do Cloud Dataproc
         </a>
         para mais informações.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.80, 1.1.71, 1.2.35
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="4 de maio de 2018" id="may_4_2018">
     4 de maio de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.79, 1.1.70, 1.2.34
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Foi corrigido o problema em que os workers preemptivos não eram excluídos dos arquivos de associação do node após saírem do cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="27 de abril de 2018" id="april_27_2018">
     27 de abril de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.78, 1.1.69, 1.2.33
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="20 de abril de 2018" id="april_20_2018">
     20 de abril de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.77, 1.1.68, 1.2.32
       </code>
       .
      </li>
      <li>
       Foi alterada a porta HTTP do Namenode de 50070 para 9870 em clusters de alta disponibilidade (HA, na sigla em inglês) na imagem de visualização. O WebHDFS, por exemplo, está acessível em
       <code>
        http://clustername-m-0:9870/webhdfs/v1/
       </code>
       . Isso é consistente com os clusters padrão e de node único no Dataproc 1.2+. Os clusters do Dataproc 1.0 e 1.1 continuarão a usar a porta 50070 para todos os modos de cluster.
      </li>
      <li>
       Foram atualizados os conectores do Cloud Storage e do BigQuery. Para mais informações, revise as
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.5">
        notas de alteração
       </a>
       no repositório do GitHub:
       <ul>
        <li>
         O conector do Cloud Storage foi atualizado para a versão 1.6.5.
        </li>
        <li>
         O conector do BigQuery foi atualizado para a versão 0.10.6.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Foi corrigido o problema em que o cluster entra no estado
       <code>
        ERROR
       </code>
       devido a um erro no redimensionamento de um grupo de instâncias gerenciadas.
      </li>
      <li>
       Backport do
       <a href="https://issues.apache.org/jira/browse/PIG-4967?attachmentOrder=desc">
        PIG-4967
       </a>
       e do
       <a href="https://issues.apache.org/jira/browse/MAPREDUCE-6762?attachmentOrder=desc">
        MAPREDUCE-6762
       </a>
       para a versão de imagem 1.2 do Cloud Datproc para corrigir uma
       <code>
        NullPointerException
       </code>
       de vez em quando em jobs do Pig.
      </li>
      <li>
       Foi corrigido um problema incomum em que o reinício de um agente do Cloud Dataproc durante uma janela pequena da operação de downscale de um cluster causava problemas de desativação dos nodes de dados.
      </li>
     </ul>
    </div>
    <h2 data-text="13 de abril de 2018" id="april_13_2018">
     13 de abril de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.76, 1.1.67, 1.2.31
       </code>
       .
      </li>
      <li>
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        Foram atualizadas as versões do software
       </a>
       na versão de imagem 1.2 do Cloud Dataproc para os seguintes produtos:
       <ul>
        <li>
         Apache Spark 2.2.0 -&gt; 2.2.1
        </li>
        <li>
         Apache Hadoop 2.8.2 -&gt; 2.8.3
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Foi corrigido um problema raro em que o agente do Cloud Dataproc falhava ao inicializar a configuração do HDFS e enviava pouquíssimos relatórios ao DataNodes.
      </li>
      <li>
       Foi corrigida a forma como o Cloud Dataproc determina que a desativação do HDFS está concluída.
      </li>
     </ul>
    </div>
    <h2 data-text="6 de abril de 2018" id="april_6_2018">
     6 de abril de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.75, 1.1.66, 1.2.30
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="30 de março de 2018" id="march_30_2018">
     30 de março de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.74, 1.1.65, 1.2.29
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="23 de março de 2018" id="march_23_2018">
     23 de março de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       das imagens do Cloud Dataproc:
       <code>
        1.0.73, 1.1.64, 1.2.28
       </code>
       .
      </li>
      <li>
       Upgrades dos conectores do Cloud Storage e do BigQuery: foram realizados os upgrades do
       <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage?hl=pt_br">
        conector do Cloud Storage
       </a>
       para
       <code>
        gcs-connector-1.6.4
       </code>
       e do
       <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/bigquery?hl=pt_br">
        conector do BigQuery
       </a>
       para
       <code>
        bigquery-connector-0.10.5
       </code>
       .
    Para mais informações, revise o repositório do GitHub:
       <a class="external" href="https://github.com/GoogleCloudPlatform/bigdata-interop/releases/tag/v1.6.4">
        registro de alterações de 19/03/2018, Google Cloud Storage 1.6.4, BigQuery 0.10.5
       </a>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="22 de março de 2018" id="march_22_2018">
     22 de março de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       As
       <a href="https://cloud.google.com/dataproc/docs/concepts/iam/granular-iam?hl=pt_br">
        permissões de IAM granular
       </a>
       atualmente estão disponíveis para jobs, operações e modelos de fluxo de trabalho do Cloud Dataproc na versão Beta.
      </li>
     </ul>
    </div>
    <h2 data-text="16 de março de 2018" id="march_16_2018">
     16 de março de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       O
       <strong>
        <a href="https://cloud.google.com/dataproc/docs/concepts/accessing/stackdriver-monitoring?hl=pt_br">
         Google Stackdriver Monitoring, versão Beta
        </a>
       </strong>
       é ativado automaticamente em clusters do Cloud Dataproc. Além disso, coleta e relata HDFS, YARN e outras métricas de cluster e de jobs do Cloud Dataproc.
      </li>
      <li>
       Adição de
       <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/connectors">
        Ação de inicialização dos conectores
       </a>
       . Com ela, os usuários atualizam os conectores do
       <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage?hl=pt_br">
        Cloud Storage
       </a>
       e do
       <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/bigquery?hl=pt_br">
        BigQuery
       </a>
       instalados nos clusters do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.73, 1.1.64, 1.2.28
       </code>
       .
      </li>
      <li>
       Foi atualizada a
       <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/conda">
        Ação de inicialização do Conda
       </a>
       para usar a versão mais recente do Miniconda, caso a versão do Spark seja pelo menos 2.2.0.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Foi corrigido um problema em que os jobs do Hive às vezes eram direcionados para um node mestre sem um Hive Server 2 no
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/high-availability?hl=pt_br">
        Modo de alta disponibilidade
       </a>
       .
    Foi resolvido
       <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/issues/205">
        um problema no GitHub
       </a>
       .
      </li>
     </ul>
    </div>
    ## 9 de março de 2018
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       O
       <a href="https://cloud.google.com/dataproc/docs/concepts/auto-zone?hl=pt_br">
        Cloud Dataproc Auto Zone
       </a>
       já está disponível.
      </li>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.71, 1.1.62, 1.2.26
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema em que o ZooKeeper não estava configurado para limpar periodicamente os diretórios de dados.
      </li>
     </ul>
    </div>
    <h2 data-text="5 de março de 2018" id="march_5_2018">
     5 de março de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        <a href="https://cloud.google.com/dataproc/docs/guides/dataproc-images?hl=pt_br">
         Imagens personalizadas do Cloud Dataproc, versão Beta
        </a>
       </strong>
       . Os usuários agora podem criar e salvar imagens personalizadas com pacotes pré-instalados. As imagens personalizadas podem então ser usadas para criar clusters do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.70, 1.1.61, 1.2.25
       </code>
       .
      </li>
      <li>
       Um campo
       <code>
        requestId
       </code>
       opcional foi adicionado a CreateCluster, UpdateCluster, DeleteCluster e SubmitJob. O campo requestId pode ser usado para evitar o processamento de solicitações duplicadas. Pedidos subsequentes com um requestId igual ao de um pedido anterior são ignorados.
      </li>
      <li>
       Aumento dos tamanhos de heap do MapReduce e do Spark History Server durante a execução em nós mestres grandes.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema em que as ações de inicialização podiam falhar ao serem executadas com o erro "errno 26 Text file is busy".
      </li>
     </ul>
    </div>
    <h2 data-text="23 de fevereiro de 2018" id="february_23_2018">
     23 de fevereiro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.69, 1.1.60, 1.2.24
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="16 de fevereiro de 2018" id="february_16_2018">
     16 de fevereiro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc:
       <code>
        1.0.68, 1.1.59, 1.2.23
       </code>
       .
      </li>
      <li>
       A atualização de rótulos de cluster agora também atualiza rótulos em discos persistentes (PDs, na sigla em inglês) anexados às VMs de trabalho mestre e primária.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema em que a exclusão do cluster poderia ficar lenta caso houvesse várias solicitações de cluster exclusivas em andamento.
      </li>
      <li>
       Correção de um problema em que os jobs eram paralisados caso o registro falhasse.
      </li>
      <li>
       Correção de um problema em que uma operação de redução de cluster falhava quando o agente dataproc identificava incorretamente o datanode HDFS desativado como paralisado.
      </li>
      <li>
       Correção de um problema em que o agente dataproc relatava incorretamente duas métricas YARN.
      </li>
     </ul>
    </div>
    <h2 data-text="9 de fevereiro de 2018" id="february_9_2018">
     9 de fevereiro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.67, 1.1.58, 1.2.22
       </code>
       .
      </li>
      <li>
       O Modo de alta disponibilidade está disponível agora em versão pública. A versão anterior era Beta.
    Os clusters do Cloud Dataproc podem ser criados com o
       <em>
        modo de alta disponibilidade
       </em>
       ativado. Esse é um recurso opcional disponível ao criar um cluster. Nesse modo, os clusters do Cloud Dataproc têm três nós mestres em vez de um. Com a alta disponibilidade do HDFS e do YARN é possível realizar operações ininterruptas do YARN e do HDFS, mesmo em caso de falhas ou reinicializações de qualquer nó único.
       <p>
        Esse recurso está disponível ao criar clusters usando a ferramenta de linha de comando
        <code>
         <a href="https://cloud.google.com/sdk/gcloud/reference/dataproc?hl=pt_br">
          gcloud
         </a>
        </code>
        , a
        <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
         API REST do Cloud Dataproc
        </a>
        e o
        <a href="https://console.developers.google.com?hl=pt_br" the="">
         Console do Google Cloud Platform
        </a>
        .
    Consulte
        <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/high-availability?hl=pt_br">
         Modo de alta disponibilidade
        </a>
        para ver mais informações.
       </p>
      </li>
      <li>
       Uma operação "Atualizar cluster" agora retorna uma operação
       <code>
        DONE
       </code>
       se a solicitação de atualização não tem nenhum trabalho a ser executado.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema em que um fluxo de trabalho pode ficar preso devido à exclusão manual de um cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="2 de fevereiro de 2018" id="february_2_2018">
     2 de fevereiro de 2018
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Inclusão de suporte para definir as
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/cluster-properties?hl=pt_br">
        propriedades do Dataproc
       </a>
       hadoop-env, mapred-env, spark-env e fio-env por meio de novos prefixos. OBSERVAÇÃO: aplica-se apenas a novas versões de imagens subsecundárias.
      </li>
      <li>
       Inclusão de um botão para vincular um cluster aos registros do
       <a href="https://cloud.google.com/dataproc/docs/concepts/accessing/stackdriver-monitoring?hl=pt_br">
        Stackdriver
       </a>
       na página de detalhes do cluster no console do Google Cloud Platform.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.66, 1.1.57, 1.2.21
       </code>
       .
      </li>
      <li>
       Upgrades de conectores do Cloud Storage e do BigQuery: foi realizado o upgrade do
       <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/cloud-storage?hl=pt_br">
        conector do Cloud Storage
       </a>
       para
       <code>
        gcs-connector-1.6.3
       </code>
       e do
       <a href="https://cloud.google.com/dataproc/docs/concepts/connectors/bigquery?hl=pt_br">
        conector do Google BigQuery
       </a>
       para
       <code>
        bigquery-connector-0.10.4
       </code>
       .
    Para saber mais informações, revise as
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/branch-1.6.x/gcs/CHANGES.txt">
        observações de alteração do Cloud Storage
       </a>
       e do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/branch-1.6.x/bigquery/CHANGES.txt">
        BigQuery
       </a>
       no repositório do GitHub.
      </li>
      <li>
       Atualizações para
       <a href="https://github.com/google/boringssl/commits/0c1eafc6feb694076e152237ad406b325e373cc0">
        BoringSSL
       </a>
       e
       <a href="https://github.com/google/conscrypt/commits/773faf663084cade0812f37899a1ddbf929c474a">
        Conscrypt
       </a>
       .
      </li>
      <li>
       Os rótulos de usuários definidos em um cluster agora se propagam para os discos anexados.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um problema do Hadoop em que um número insuficiente de Datanodes criava relatórios.
      </li>
      <li>
       Aceleramos
       <code>
        commitJob
       </code>
       no Cloud Storage para jobs com muitas tarefas de última etapa (redução).
      </li>
     </ul>
    </div>
    <h2 data-text="10 de janeiro de 2018" id="january_10_2018">
     10 de janeiro de 2018
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.63, 1.1.54, 1.2.18
       </code>
       .
      </li>
      <li>
       A tentativa automática do commitJob, introduzida no
       <a class="external" href="https://issues.apache.org/jira/browse/MAPREDUCE-5485">
        MAPREDUCE-5485
       </a>
       agora é ativada por padrão. Configure o
       <code>
        mapreduce.fileoutputcommitter.failures.attempt
       </code>
       como
       <code>
        1
       </code>
       para voltar ao comportamento antigo.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Patch aplicado a CVE-2017-5754 ("Meltdown") juntamente com outros patches de segurança referenciados na
       <a class="external" href="https://security-tracker.debian.org/tracker/DSA-4082-1">
        DSA-4082-1
       </a>
       .
      </li>
      <li>
       Os SSDs locais agora são devidamente reformatados na inicialização após uma migração de host inesperada. Anteriormente, essas migrações de host em nodes com SSDs locais poderiam fazer com que os workers se tornassem extintos.
      </li>
      <li>
       Confiabilidade aprimorada na inicialização do cluster de alta disponibilidade para casos em que uma ou mais inicializações de mestres é atrasada.
      </li>
     </ul>
    </div>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Agora é possível instanciar os fluxos de trabalho do Dataproc diretamente sem criar um WorkflowTemplate usando o novo
       <a href="https://cloud.google.com/dataproc/docs/reference/rest/v1beta2/projects.regions.workflowTemplates/instantiateInline?hl=pt_br">
        método InstantiateInline
       </a>
       .
      </li>
      <li>
       Anunciamos a versão Beta dos
       <a href="https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-pd-ssd?hl=pt_br">
        discos de inicialização da unidade de estado sólido permanente do Cloud Dataproc (PD-SSD, na sigla em inglês)
       </a>
       . Com eles, é possível criar clusters que usam as PD-SSDs nos discos de inicialização dos nós mestre e de trabalho.
      </li>
      <li>
       O Cloud Dataproc agora está disponível na
       <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
        região
       </a>
       <code>
        northamerica-northeast1
       </code>
       (Montréal, Canadá).
      </li>
      <li>
       O Cloud Dataproc agora está disponível na
       <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
        região
       </a>
       <code>
        europe-west4
       </code>
       (Holanda).
      </li>
     </ul>
    </div>
    <h2 data-text="20 de dezembro de 2017" id="december_20_2017">
     20 de dezembro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Agora é possível selecionar uma
       <a href="https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu?hl=pt_br">
        plataforma mínima de CPU
       </a>
       ao criar um cluster do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       O recurso de desativação otimizada do Google Cloud Dataproc está na versão pública. A versão anterior era a Beta. Com ele, é possível remover nodes do cluster sem interromper os jobs em andamento. Um tempo limite especificado pelo usuário determina a espera pela conclusão dos jobs em andamento antes de forçar a remoção dos nós. Esse recurso está disponível ao atualizar clusters usando a ferramenta de linha de comando
       <code>
        <a href="https://cloud.google.com/sdk/gcloud/reference/dataproc?hl=pt_br">
         gcloud
        </a>
       </code>
       , a
       <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
        API REST do Cloud Dataproc
       </a>
       e o
       <a href="https://console.developers.google.com?hl=pt_br" the="">
        Console do Google Cloud Platform
       </a>
       .
    Consulte
       <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/scaling-clusters?hl=pt_br#graceful_decommissioning">
        Desativação otimizada
       </a>
       para saber mais informações.
      </li>
      <li>
       O recurso de clusters de node único está na versão pública (antes, estava na Beta).
    Eles são clusters do Cloud Dataproc com apenas um node que atua como mestre e worker. Os clusters de nó único são úteis em diversas atividades, incluindo desenvolvimento, educação e ciência de dados leves.
       <p>
        Esse recurso está disponível ao criar clusters usando a ferramenta de linha de comando
        <code>
         <a href="https://cloud.google.com/sdk/gcloud/reference/dataproc?hl=pt_br">
          gcloud
         </a>
        </code>
        , a
        <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
         API REST do Cloud Dataproc
        </a>
        e o
        <a href="https://console.developers.google.com?hl=pt_br" the="">
         Console do Google Cloud Platform
        </a>
        . Consulte o artigo
        <a href="https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/single-node-clusters?hl=pt_br">
         Clusters de nó único
        </a>
        para saber mais.
       </p>
      </li>
     </ul>
    </div>
    <h2 data-text="8 de dezembro de 2017" id="december_8_2017">
     8 de dezembro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       O recurso de jobs reinicializáveis está disponível agora em versão pública. A versão anterior era Beta. Os jobs do Cloud Dataproc têm uma configuração opcional para reinicializar jobs com falha. Ao definir um job para reinicializar, você especifica o número máximo de tentativas por hora. O máximo são 10 tentativas. Com os jobs reinicializáveis, você reduz os tipos de falhas. Eles são úteis principalmente em jobs de streaming e de longa duração. Esse recurso está disponível ao enviar jobs usando a ferramenta de linha de comando
       <code>
        <a href="https://cloud.google.com/sdk/gcloud/reference/dataproc?hl=pt_br">
         gcloud
        </a>
       </code>
       , a
       <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
        API REST do Cloud Dataproc
       </a>
       e o
       <a href="https://console.developers.google.com?hl=pt_br" the="">
        Console do Google Cloud Platform
       </a>
       .
    Consulte o artigo
       <a href="https://cloud.google.com/dataproc/docs/concepts/jobs/restartable-jobs?hl=pt_br">
        Jobs reinicializáveis
       </a>
       para saber mais informações.
      </li>
     </ul>
    </div>
    <h2 data-text="17 de novembro de 2017" id="november_17_2017">
     17 de novembro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.58, 1.1.49, 1.2.13
       </code>
       .
      </li>
      <li>
       Adicionada uma nova otimização que aumenta o desempenho das operações de lista para jobs e operações ao usar tags.
      </li>
     </ul>
    </div>
    <h2 data-text="10 de novembro de 2017" id="november_10_2017">
     10 de novembro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.57, 1.1.48, 1.2.12
       </code>
       .
      </li>
      <li>
       Upgrade do Apache Hadoop para
       <code>
        2.8.2
       </code>
       na imagem do Cloud Dataproc 1.2.
      </li>
     </ul>
    </div>
    <h2 data-text="1º de novembro de 2017" id="november_1_2017">
     1º de novembro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Ao usar
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=pt_br#adding_a_cluster_selector_to_a_template">
        seletores de cluster de fluxo de trabalho
       </a>
       , se mais de um cluster corresponder aos rótulos especificados, o Cloud Dataproc selecionará o cluster com a memória YARN que tiver mais espaço livre. Essa alteração substitui o comportamento anterior de escolher um cluster aleatório com o rótulo correspondente.
      </li>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.56, 1.1.47, 1.2.11
       </code>
       .
      </li>
      <li>
       Os erros HTTP
       <code>
        404
       </code>
       e
       <code>
        409
       </code>
       agora mostrarão o nome completo do recurso para fornecer mensagens de erro mais úteis.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Corrigido um bug que impedia modelos de fluxo de trabalho de lidar com
       <code>
        /locations/
       </code>
       em nomes de recursos.
      </li>
     </ul>
    </div>
    <h2 data-text="31 de outubro de 2017" id="october_31_2017">
     31 de outubro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      Agora o Cloud Dataproc está disponível na
      <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
       região
      </a>
      <code>
       asia-south1
      </code>
      (Mumbai, Índia).
     </p>
    </div>
    <h2 data-text="24 de outubro de 2017" id="october_24_2017">
     24 de outubro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Todas as operações do
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=pt_br">
        <code>
         WorkflowTemplate
        </code>
       </a>
       após 27 de outubro de 2017 serão registradas no
       <a href="https://cloud.google.com/logging/docs/audit?hl=pt_br">
        Cloud Audit Logging
       </a>
       .
      </li>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.55, 1.1.46, 1.2.10
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="17 de outubro de 2017" id="october_17_2017">
     17 de outubro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.54, 1.1.45, 1.2.9
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um bug em que o keep-alive HTTP causava erros
       <code>
        java.lang.NullPointerException: ssl == null
       </code>
       durante o acesso ao Cloud Storage.
      </li>
      <li>
       A
       <a class="external" href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/oozie">
        ação de inicialização do Apache Oozie
       </a>
       foi corrigida para funcionar com o Cloud Dataproc 1.2.
      </li>
     </ul>
    </div>
    <h2 data-text="11 de outubro de 2017" id="october_11_2017">
     11 de outubro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       O
       <code>
        fluentd
       </code>
       dos clusters do Cloud Dataproc foi reconfigurado para concatenar mensagens de erro de várias linhas. Isso facilitará a localização das mensagens de erro.
      </li>
      <li>
       Os clusters criados com os
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=pt_br">
        fluxos de trabalho do Cloud Dataproc
       </a>
       agora usam o
       <a href="https://cloud.google.com/dataproc/docs/concepts/auto-zone?hl=pt_br">
        posicionamento em zona automática
       </a>
       .
      </li>
      <li>
       A partir desta versão, as versões subsecundárias para as imagens do Cloud Dataproc serão mencionadas nas notas da versão.
      </li>
      <li>
       Há novas
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        versões subsecundárias
       </a>
       de imagens do Cloud Dataproc -
       <code>
        1.0.53, 1.1.44, 1.2.8
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um bug ao ler arquivos ORC no Hive 2.1 no Cloud Dataproc 1.1.
    Para corrigir esse problema, o
       <a class="external" href="https://issues.apache.org/jira/browse/HIVE-17448">
        HIVE-17448
       </a>
       recebeu um patch para o Hive 2.1.
      </li>
      <li>
       Correção de um problema em que o Spark memoryOverhead era configurado incorretamente para clusters com máquinas mestres com muita memória e trabalhos com pouca memória. O memoryOverhead agora está configurado corretamente para esse tipo de cluster.
      </li>
      <li>
       A lógica do agente do Cloud Dataproc foi melhorada para iniciar jobs na ordem em que foram enviados.
      </li>
      <li>
       A
       <a class="external" href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/hue">
        ação de inicialização do HUE
       </a>
       foi corrigida para funcionar com o Cloud Dataproc 1.2.
      </li>
      <li>
       Correção de um bug em que as falhas na ação de inicialização não eram devidamente relatadas.
      </li>
     </ul>
    </div>
    <h2 data-text="4 de outubro de 2017" id="october_4_2017">
     4 de outubro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Modelos de fluxo de trabalho Cloud Dataproc
       </strong>
       (Beta): este novo recurso do Cloud Dataproc permite que os jobs sejam compostos em um gráfico para execução em um conjunto temporário ou existente. O modelo pode criar um cluster, executar jobs e excluir o cluster quando o fluxo de trabalho estiver concluído. O andamento do gráfico pode ser monitorado com a pesquisa de uma única operação.
Consulte
       <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=pt_br">
        Modelos de fluxo de trabalho - Visão geral
       </a>
       para mais informações.
      </li>
     </ul>
    </div>
    <h2 data-text="27 de setembro de 2017" id="september_27_2017">
     27 de setembro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        IAM Granular do Cloud Dataproc
       </strong>
       <sup>
        Beta
       </sup>
       : agora é possível configurar papéis IAM e permissões correspondentes por cluster. Isso oferece um mecanismo para ter diferentes configurações de IAM de clusters do Cloud Dataproc. Consulte a
       <a href="https://cloud.google.com/dataproc/docs/concepts/iam?hl=pt_br#cloud_dataproc_granular_iam">
        documentação IAM do Cloud Dataproc
       </a>
       para mais informações.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Correção de um bug que impedia o Apache Pig e o Apache Tez de funcionarem juntos no
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        Cloud Dataproc 1.2
       </a>
       .
  Essa correção foi aplicada ao Cloud Dataproc 1.1 em uma versão anterior.
      </li>
      <li>
       Correção de um bug envolvendo a validação do esquema Hive. Essa correção trata especificamente do
       <a class="external" href="https://issues.apache.org/jira/browse/HIVE-17448">
        HIVE-17448
       </a>
       e do
       <a class="external" href="https://issues.apache.org/jira/browse/HIVE-12274">
        HIVE-12274
       </a>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="19 de setembro de 2017" id="september_19_2017">
     19 de setembro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       <strong>
        Novas versões de imagens subsecundárias
       </strong>
       : as versões de imagens subsecundárias mais recentes para 1.0, 1.1 e 1.2 são agora mapeadas respectivamente para
       <code>
        1.0.51
       </code>
       ,
       <code>
        1.1.42
       </code>
       e
       <code>
        1.2.6
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="6 de setembro de 2017" id="september_6_2017">
     6 de setembro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Exclusão Programada do Cluster
       </strong>
       <sup>
        Beta
       </sup>
       : agora é possível criar clusters do Cloud Dataproc com uma política de exclusão programada. Os clusters podem ser programados para exclusão após uma duração especificada ou em um horário especificado, ou após um período de inatividade especificado. Consulte
       <a href="https://cloud.google.com/dataproc/docs/concepts/scheduled-deletion?hl=pt_br">
        Exclusão programada de cluster
       </a>
       para mais informações.
      </li>
     </ul>
    </div>
    <h2 data-text="5 de setembro de 2017" id="september_5_2017">
     5 de setembro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      O Cloud Dataproc atualmente está disponível na
      <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
       região
      </a>
      <code>
       southamerica-east1
      </code>
      (São Paulo, Brasil).
     </p>
    </div>
    <h2 data-text="18 de agosto de 2017" id="august_18_2017">
     18 de agosto de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       <strong>
        Novas versões de imagens subsecundárias
       </strong>
       : as versões de imagens subsecundárias mais recentes para 1.0, 1.1 e 1.2 são agora mapeadas respectivamente para
       <code>
        1.0.49
       </code>
       ,
       <code>
        1.1.40
       </code>
       e
       <code>
        1.2.4
       </code>
       .
      </li>
      <li>
       Todos os clusters do Cloud Dataproc agora têm um rótulo
       <code>
        goog-dataproc-cluster-name
       </code>
       que se propaga aos recursos subjacentes do Google Compute Engine e pode ser usado para determinar os custos combinados do Cloud Dataproc em dados de faturamento exportados.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Os drivers PySpark agora são lançados com um código do grupo de processo alterado para permitir que o agente do Cloud Dataproc limpe corretamente os jobs cancelados ou com comportamento inadequado.
      </li>
      <li>
       Correção de um bug em que a atualização de rótulos de clusters e o número de workers secundários em uma única atualização resultavam no travamento de uma operação de atualização e em um cluster que não podia ser excluído.
      </li>
     </ul>
    </div>
    <h2 data-text="8 de agosto de 2017" id="august_8_2017">
     8 de agosto de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      A partir de hoje, o
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
       Cloud Dataproc 1.2
      </a>
      será a versão padrão para novos clusters. Para usar versões mais antigas do Cloud Dataproc, você precisará selecionar manualmente a versão na criação do cluster.
     </p>
    </div>
    <h2 data-text="4 de agosto de 2017" id="august_4_2017">
     4 de agosto de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      <strong>
       Desativação otimizada
      </strong>
      : os clusters do Cloud Dataproc que executam o
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
       Cloud Dataproc 1.2 ou posterior
      </a>
      atualmente são compatíveis com a
      <a href="https://issues.apache.org/jira/browse/YARN-914">
       desativação otimizada YARN
      </a>
      . A desativação otimizada permite a remoção de nodes do cluster sem interromper os jobs em andamento. Um tempo limite especificado pelo usuário determina a espera pela conclusão dos jobs em andamento antes de remover os nodes de modo forçado. A
      <a href="https://cloud.google.com/dataproc/docs/concepts/scaling-clusters?hl=pt_br#graceful_decommissioning">
       documentação de escalonamento do Cloud Dataproc
      </a>
      contém detalhes sobre como ativar a desativação otimizada.
     </p>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      O Apache Hadoop do Cloud Dataproc 1.2 foi atualizado para a versão 2.8.1
     </p>
    </div>
    <h2 data-text="1 de agosto de 2017" id="august_1_2017">
     1 de agosto de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      O Cloud Dataproc atualmente está disponível na
      <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br#available">
       região
      </a>
      <code>
       europe-west3
      </code>
      (Frankfurt, Alemanha).
     </p>
    </div>
    <h2 data-text="21 de julho de 2017" id="july_21_2017">
     21 de julho de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Cloud Dataproc 1.2
       </strong>
       : uma nova versão de imagem do Cloud Dataproc já está disponível:
       <code>
        1.2
       </code>
       . Daqui a duas semanas, ela será a versão de imagem padrão dos novos clusters. Consulte a
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        lista de versões do Cloud Dataproc
       </a>
       para mais informações. Algumas mudanças importantes incluídas nesta nova versão de imagem:
       <ul>
        <li>
         O
         <a href="http://spark.apache.org">
          Apache Spark
         </a>
         foi atualizado para a versão 2.2.0.
        </li>
        <li>
         O
         <a href="http://hadoop.apache.org">
          Apache Hadoop
         </a>
         foi atualizado para a versão 2.8.0.
        </li>
        <li>
         O provedor de segurança padrão (SSL) usado pelo conector do Cloud Storage foi alterado para um que é baseado em
         <a href="https://github.com/google/conscrypt">
          Conscrypt
         </a>
         . Essa alteração utilizará a CPU de maneira mais eficiente nas operações com SSL. Em muitos casos, essa alteração resultará em melhor desempenho de leitura e gravação entre o Cloud Dataproc e o Cloud Storage.
        </li>
        <li>
         O tamanho do bloco relatado do Cloud Storage agora é de 128 MB.
        </li>
        <li>
         A configuração de memória do Hadoop e Spark foi ajustada para melhorar o desempenho e a estabilidade.
        </li>
        <li>
         Os daemons HDFS não usam mais portas temporárias de acordo com novas atribuições de porta descritas em
         <a href="https://issues.apache.org/jira/browse/HDFS-9427">
          HDFS-9427
         </a>
         . Isso elimina certas condições raras de corrida que, de vez em quando, podem causar falhas de inicialização do daemon.
        </li>
        <li>
         O ordenamento justo do YARN Capacity Scheduler de
         <a href="https://issues.apache.org/jira/browse/YARN-3319">
          YARN-3319
         </a>
         agora está ativado por padrão.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      A partir da versão do Cloud Dataproc 1.2, os jars de inicialização ALPN não serão mais fornecidos na imagem do Cloud Dataproc. Para evitar falha no job do Spark, faça upgrade das versões de cliente do Cloud Bigtable e agrupe
      <code>
       boringssl-static
      </code>
      com os jobs do Cloud Dataproc. Nosso
      <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions">
       repositório de ações de inicialização
      </a>
      contém esse tipo de ação para voltar ao comportamento anterior (obsoleto) de incluir o jar de inicialização
      <code>
       jetty-alpn
      </code>
      . Essa alteração só terá impacto se você usar o Cloud Bigtable ou outros clientes Java gRPC do Cloud Dataproc.
     </p>
    </div>
    <h2 data-text="11 de julho de 2017" id="july_11_2017">
     11 de julho de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Spark 2.2.0 em Visualização
       </strong>
       : a
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        imagem de visualização
       </a>
       do Cloud Dataproc foi atualizada para o Spark 2.2.0.
      </li>
     </ul>
    </div>
    <h2 data-text="28 de junho de 2017" id="june_28_2017">
     28 de junho de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Disponibilidade dos pontos de extremidade regionais
       </strong>
       : os
       <a href="https://cloud.google.com/dataproc/docs/concepts/regional-endpoints?hl=pt_br">
        pontos de extremidade regionais
       </a>
       do Cloud Dataproc já estão disponíveis.
      </li>
      <li>
       <strong>
        Autozone
        <sup>
         Beta
        </sup>
       </strong>
       : quando você cria um novo cluster é possível usar, como alternativa à escolha de uma zona, o
       <a href="https://cloud.google.com/dataproc/docs/concepts/auto-zone?hl=pt_br">
        recurso zona automática do Cloud Dataproc
       </a>
       . A seleção de zona é feita dentro da região escolhida para a colocação do cluster.
      </li>
      <li>
       <p>
        <strong>
         Conector do Conscrypt para Cloud Storage
        </strong>
        : o provedor de segurança padrão (SSL, na sigla em inglês) usado pelo conector do Cloud Storage na
        <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
         imagem de visualização do Cloud Dataproc
        </a>
        foi alterado para outro baseado no
        <a href="https://github.com/google/conscrypt">
         Conscrypt
        </a>
        . Essa alteração utilizará a CPU de maneira mais eficiente nas operações com SSL. Em muitos casos, essa alteração resultará em melhor desempenho de leitura e gravação entre o Cloud Dataproc e o Cloud Storage.
       </p>
      </li>
     </ul>
    </div>
    <h2 data-text="26 de junho de 2017" id="june_26_2017">
     26 de junho de 2017
    </h2>
    <div class="release-deprecated">
     <strong>
      DEPRECATED:
     </strong>
     <ul>
      <li>
       As Cloud Dataproc APIs
       <code>
        v1alpha1
       </code>
       e
       <code>
        v1beta1
       </code>
       agora estão obsoletas e não podem ser usadas. Em vez disso, use a
       <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
        API
        <code>
         v1
        </code>
       </a>
       atual.
      </li>
     </ul>
    </div>
    <h2 data-text="20 de junho de 2017" id="june_20_2017">
     20 de junho de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      O Cloud Dataproc agora está disponível na
      <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones?hl=pt_br">
       região
      </a>
      <code>
       australia-southeast1
      </code>
      (Sydney).
     </p>
    </div>
    <h2 data-text="6 de junho de 2017" id="june_6_2017">
     6 de junho de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      O Cloud Dataproc está agora disponível na região
      <code>
       europe-west2
      </code>
      (Londres).
     </p>
    </div>
    <h2 data-text="28 de abril de 2017" id="april_28_2017">
     28 de abril de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      <strong>
       Upgrade de conectores do Cloud Storage e do BigQuery
      </strong>
      : foram realizados os upgrades do conector do Cloud Storage para
      <code>
       gcs-connector-1.6.1
      </code>
      e do conector do BigQuery para
      <code>
       bigquery-connector-0.10.2
      </code>
      . Para ver mais informações, leia as observações de alteração do
      <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/CHANGES.txt">
       Cloud Storage
      </a>
      ou do
      <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/bigquery/CHANGES.txt">
       BigQuery
      </a>
      no repositório do GitHub.
     </p>
    </div>
    <div class="release-deprecated">
     <strong>
      DEPRECATED:
     </strong>
     <p>
      As Cloud Dataproc APIs
      <code>
       v1alpha1
      </code>
      e
      <code>
       v1beta1
      </code>
      agora estão obsoletas e não podem ser usadas. Em vez disso, use a
      <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
       API
       <code>
        v1
       </code>
      </a>
      atual.
     </p>
    </div>
    <h2 data-text="21 de abril de 2017" id="april_21_2017">
     21 de abril de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Na
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        imagem de visualização
       </a>
       com base no Hadoop 2.8, o YARN Capacity Scheduler foi definido para usar a política de ordenamento justo em vez do FIFO.
      </li>
      <li>
       Os
       <a href="https://cloud.google.com/dataproc/docs/concepts/iam?hl=pt_br">
        nomes dos papéis do IAM do Cloud Dataproc
       </a>
       foram atualizados para serem consistentes com outros produtos do Google Cloud.
      </li>
      <li>
       Novas permissões de registro e monitoramento foram incluídas no
       <a href="https://cloud.google.com/dataproc/docs/concepts/iam?hl=pt_br#cloud_dataproc_roles">
        papel
        <code>
         Dataproc/Dataproc Worker
        </code>
        do IAM
       </a>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="12 de abril de 2017" id="april_12_2017">
     12 de abril de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      O Apache Hive no
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
       Cloud Dataproc 1.1
      </a>
      foi atualizado para a versão 2.1.1.
     </p>
    </div>
    <h2 data-text="7 de abril de 2017" id="april_7_2017">
     7 de abril de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      <strong>
       Papel do IAM de trabalho do Cloud Dataproc
      </strong>
      : foi adicionado um novo papel do IAM do Cloud Dataproc chamado
      <a href="https://cloud.google.com/dataproc/docs/concepts/iam?hl=pt_br#cloud_dataproc_roles">
       <code>
        Dataproc/Dataproc Worker
       </code>
      </a>
      . Ele se destina especificamente ao uso com
      <a href="https://cloud.google.com/dataproc/docs/concepts/service-accounts?hl=pt_br">
       contas de serviço
      </a>
      .
     </p>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      O
      <a href="https://cloud.google.com/dataproc/docs/release-notes/service?hl=pt_br#march_30_2017">
       provedor de segurança do Conscrypt
      </a>
      foi temporariamente alterado do padrão para um provedor de segurança opcional. Essa alteração foi feita devido a incompatibilidades com algumas cargas de trabalho. O provedor do Conscrypt será reativado como padrão posteriormente com o lançamento do Cloud Dataproc 1.2. Enquanto isso, você pode reativar o provedor do Conscrypt ao criar um cluster especificando esta
      <a href="https://cloud.google.com/dataproc/docs/concepts/cluster-properties?hl=pt_br">
       propriedade do Cloud Dataproc
      </a>
      :
     </p>
     <pre>--properties dataproc:dataproc.conscrypt.provider.enable=true</pre>
     <p>
     </p>
    </div>
    <h2 data-text="30 de março de 2017" id="march_30_2017">
     30 de março de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      <strong>
       Conector do Conscrypt para Cloud Storage
      </strong>
      : o provedor de segurança padrão (SSL) usado pelo conector do Cloud Storage foi alterado para outro baseado no
      <a href="https://github.com/google/conscrypt">
       Conscrypt
      </a>
      . Essa alteração utilizará a CPU de maneira mais eficiente nas operações com SSL. Em muitos casos, essa alteração resultará em melhor desempenho de leitura e gravação entre o Cloud Dataproc e o Cloud Storage.
     </p>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      As atualizações para
      <a href="https://cloud.google.com/dataproc/docs/concepts/labels?hl=pt_br">
       rótulos de usuário
      </a>
      aplicadas aos clusters do Cloud Dataproc agora serão aplicadas aos modelos de grupo de instâncias gerenciadas. Como as
      <a href="https://cloud.google.com/dataproc/docs/concepts/preemptible-vms?hl=pt_br">
       máquinas virtuais preemptivas
      </a>
      são incluídas em um grupo de instâncias gerenciadas, as atualizações nos rótulos agora são aplicadas às VMs preemptivas.
     </p>
    </div>
    <h2 data-text="17 de março de 2017" id="march_17_2017">
     17 de março de 2017
    </h2>
    <div class="release-deprecated">
     <strong>
      DEPRECATED:
     </strong>
     <p>
      Conforme mencionado nas
      <a href="https://cloud.google.com/dataproc/docs/release-notes/service?hl=pt_br#february_9_2017">
       notas da versão de 9 de fevereiro
      </a>
      , os registros de auditoria do Cloud referentes ao Cloud Dataproc não são mais emitidos para o tipo de recurso
      <code>
       dataproc_cluster
      </code>
      . A partir desta versão, eles serão emitidos para
      <code>
       cloud_dataproc_cluster
      </code>
      .
     </p>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      O comando
      <code>
       <a href="https://cloud.google.com/sdk/gcloud/reference/dataproc?hl=pt_br">
        gcloud
       </a>
      </code>
      agora
      <a href="https://cloud.google.com/sdk/docs/release-notes?hl=pt_br#14700_2017-03-15">
       requer um traço duplo
      </a>
      (
      <code>
       --
      </code>
      ) entre os argumentos específicos do gcloud e os argumentos para esses comandos. Por exemplo, se você já usou este comando:
     </p>
     <pre>gcloud dataproc jobs submit spark --cluster example-cluster \
--class sample_class --jars jar_file 1000</pre>
     O novo formato dele requer um traço duplo entre espaços:
     <pre>gcloud dataproc jobs submit spark --cluster example-cluster \
--class sample_class --jars jar_file <b>-- 1000</b></pre>
     .
    </div>
    <h2 data-text="7 de março de 2017" id="march_7_2017">
     7 de março de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Rótulos de usuário
       </strong>
       : esses
       <a href="https://cloud.google.com/dataproc/docs/concepts/labels?hl=pt_br">
        rótulos com recursos do Cloud Dataproc
       </a>
       já estão disponíveis. Você pode adicionar e atualizar rótulos nos clusters e jobs do Cloud Dataproc. Os rótulos são úteis em situações como contabilidade de custos, distribuição de trabalho e testes.
      </li>
      <li>
       <strong>
        Anexamos GPUs a clusters
        <sup>
         Beta
        </sup>
       </strong>
       : os clusters do Cloud Dataproc atualmente são compatíveis com
       <a href="https://cloud.google.com/compute/docs/gpus?hl=pt_br">
        GPUs do Compute Engine
       </a>
       . Os clusters podem ter
       <a href="https://cloud.google.com/dataproc/docs/concepts/gpu-clusters?hl=pt_br">
        de uma a oito GPUs anexadas aos nós mestre e de trabalho
       </a>
       . É possível usá-las com aplicativos no cluster, como o Apache Spark. O anexo de GPUs pode beneficiar alguns tipos de jobs de processamento de dados.
      </li>
     </ul>
    </div>
    <h2 data-text="1º de março de 2017" id="march_1_2017">
     1º de março de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Jobs reinicializáveis
        <sup>
         Beta
        </sup>
       </strong>
       : os jobs do Cloud Dataproc têm agora uma
       <a href="https://cloud.google.com/dataproc/docs/concepts/restartable-jobs?hl=pt_br">
        configuração opcional para reiniciar jobs
       </a>
       com falha. Ao definir a reinicialização de um job, é preciso especificar o número máximo de novas tentativas por hora. Com os jobs reinicializáveis, você reduz os tipos comuns de falhas. Eles são úteis principalmente em jobs de streaming e de longa duração.
      </li>
      <li>
       <strong>
        Clusters de nó único
        <sup>
         Beta
        </sup>
       </strong>
       :
       <a href="https://cloud.google.com/dataproc/docs/concepts/single-node-clusters?hl=pt_br">
        clusters de nó único
       </a>
       são clusters do Cloud Dataproc com apenas um nó que funcionam como mestre e trabalho. Eles são úteis em diversas atividades, incluindo desenvolvimento, educação e ciência de dados leves.
      </li>
     </ul>
    </div>
    <h2 data-text="9 de fevereiro de 2017" id="february_9_2017">
     9 de fevereiro de 2017
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       <strong>
        Alterações na geração de registros do Cloud Dataproc Stackdriver
       </strong>
       <ul>
        <li>
         Com novas imagens, os registros do cluster agora são exportados para o Stackdriver como o tipo de recurso
         <code>
          cloud_dataproc_cluster
         </code>
         (antigo
         <code>
          dataproc_cluster
         </code>
         ).
        </li>
        <li>
         Os registros de auditoria do Cloud são emitidos para ambos
         <code>
          cloud_dataproc_cluster
         </code>
         e
         <code>
          dataproc_cluster
         </code>
         (com uso suspenso) até a versão de 9 de março.
        </li>
        <li>
         Os registros do Stackdriver das novas imagens são indexados primeiro por nome do cluster e, depois, por UUID para ajudar a filtrá-los por nome ou instância do cluster.
        </li>
       </ul>
      </li>
      <li>
       <strong>
        Alterações no monitoramento do Cloud Dataproc Stackdriver
       </strong>
       <ul>
        <li>
         As
         <a href="https://cloud.google.com/logging/docs/view/logs_based_metrics?hl=pt_br">
          métricas com base em registros
         </a>
         do Cloud Dataproc agora são visíveis no Stackdriver.
        </li>
       </ul>
      </li>
      <li>
       <strong>
        Alterações nos rótulos de usuário do Cloud Dataproc
       </strong>
       <ul>
        <li>
         Agora é possível atualizar os
         <a href="https://cloud.google.com/dataproc/docs/concepts/labels?hl=pt_br">
          rótulos de usuários
         </a>
         em jobs do Dataproc com a ferramenta de linha de comando
         <a href="https://cloud.google.com/dataproc/docs/gcloud-installation?hl=pt_br">
          gcloud
         </a>
         ou a
         <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
          API REST do Cloud Dataproc
         </a>
         .
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <h2 data-text="19 de janeiro de 2017" id="january_19_2017">
     19 de janeiro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Visualização do Cloud Dataproc
        <code>
         1.2
        </code>
       </strong>
       : a
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        <code>
         preview image
        </code>
       </a>
       foi atualizada para refletir a versão planejada do Cloud Dataproc
       <code>
        1.2
       </code>
       . Essa imagem inclui o Apache Spark 2.1 e o Apache Hadoop 2.8-SNAPSHOT. Ela foi disponibilizada para podermos conceder acesso ao Hadoop 2.8 (assim que ele for oficialmente lançado) no Dataproc 1.2 e às versões release candidate.
      </li>
     </ul>
    </div>
    <h2 data-text="5 de janeiro de 2017" id="january_5_2017">
     5 de janeiro de 2017
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Upgrade de conectores do Cloud Storage e do BigQuery
       </strong>
       : foram realizados os upgrades do conector do Cloud Storage para
       <code>
        gcs-connector-1.6.0
       </code>
       e do conector do BigQuery para
       <code>
        bigquery-connector-0.10.1
       </code>
       . Para ver mais informações, leia as observações de alteração do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/CHANGES.txt">
        Cloud Storage
       </a>
       ou do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/bigquery/CHANGES.txt">
        BigQuery
       </a>
       no repositório do GitHub.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       O comando
       <code>
        <a href="https://cloud.google.com/dataproc/docs/support/diagnose-command?hl=pt_br">
         diagnose
        </a>
       </code>
       foi atualizado para incluir a saída do jstack do agente e dos drivers gerados.
      </li>
     </ul>
    </div>
    <h2 data-text="16 de dezembro de 2016" id="december_16_2016">
     16 de dezembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Instalação do agente do Google Stackdriver
       </strong>
       : agora, o agente de monitoramento do
       <a href="https://cloud.google.com/stackdriver?hl=pt_br">
        Stackdriver
       </a>
       é instalado por padrão nos clusters do Cloud Dataproc. A
       <a href="https://cloud.google.com/dataproc/docs/concepts/stackdriver-monitoring?hl=pt_br">
        documentação de monitoramento do Cloud Dataproc Stackdriver
       </a>
       tem informações sobre como usar o monitoramento do Stackdriver com o Cloud Dataproc. É possível ativar e exibir o agente de monitoramento e geração de registros ajustando as
       <a href="https://cloud.google.com/dataproc/docs/concepts/cluster-properties?hl=pt_br">
        propriedades do cluster
       </a>
       ao criá-lo.
      </li>
      <li>
       <strong>
        Cloud Dataproc 1.1.15 e 1.0.24
       </strong>
       : as imagens 1.1 e 1.0 receberam atualizações, correções de bugs e melhorias não impactantes.
      </li>
     </ul>
    </div>
    <h2 data-text="7 de dezembro de 2016" id="december_7_2016">
     7 de dezembro de 2016
    </h2>
    <div class="release-issue">
     <strong>
      ISSUE:
     </strong>
     <ul>
      <li>
       A partir desta versão,
       <strong>
        a API Google Cloud Dataproc precisa ser ativada no projeto para o Cloud Dataproc funcionar corretamente.
       </strong>
       Use o
       <a href="https://console.cloud.google.com/apis/dashboard?hl=pt_br">
        console do Google Cloud Platform
       </a>
       para ativar a API Cloud Dataproc. Projetos existentes com a API Cloud Dataproc ativada não serão afetados.
      </li>
     </ul>
    </div>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Cloud Dataproc 1.1.14 e 1.0.23
       </strong>
       : as imagens 1.1 e 1.0 receberam atualizações, correções de bugs e melhorias não impactantes.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Maior número de situações em que os serviços do Cloud-Dataproc são automaticamente reiniciados por
       <code>
        systemd
       </code>
       nos clusters em caso de comportamento inesperado ou problemático.
      </li>
     </ul>
    </div>
    <h2 data-text="29 de novembro de 2016" id="november_29_2016">
     29 de novembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Suporte à conta de serviço personalizada
       </strong>
       : ao criar um cluster do Cloud Dataproc, você agora pode especificar uma conta de serviço gerenciada pelo usuário (não padrão). Essa conta de serviço será usada para executar as máquinas virtuais do Google Compute Engine no cluster. Isso possibilita permissões muito mais minuciosas para os serviços de cada cluster. Consulte a
       <a href="https://cloud.google.com/dataproc/docs/concepts/service-accounts?hl=pt_br">
        documentação de conta de serviço
       </a>
       para mais informações.
      </li>
      <li>
       <strong>
        Cloud Dataproc 1.1.13 e 1.0.22
       </strong>
       : a imagem 1.1 do Cloud Dataproc foi atualizada para incluir suporte ao Apache Spark 2.0.2, Apache Zeppelin 0.6.2 e Apache Flink 1.1.3. As imagens 1.1 e 1.0 também foram atualizadas com correções de bugs e melhorias não impactantes. Consulte a
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning?hl=pt_br">
        Lista das versões do Cloud Dataproc
       </a>
       para mais informações sobre as versões de imagem do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <h2 data-text="14 de novembro de 2016" id="november_14_2016">
     14 de novembro de 2016
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Problema corrigido do argumento
       <code>
        --jars
       </code>
       que estava ausente do comando
       <code>
        gcloud dataproc jobs submit pyspark
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="8 de novembro de 2016" id="november_8_2016">
     8 de novembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Upgrade do conector do Google BigQuery
       </strong>
       : foi realizado o upgrade do conector do BigQuery para
       <code>
        bigquery-connector-0.10.1-SNAPSHOT
       </code>
       . Esta versão introduz o novo
       <code>
        IndirectBigQueryOutputFormat
       </code>
       , que usa formatos de saída do Hadoop para gravar diretamente em um intervalo temporário do Cloud Storage e emite um job de carga único do BigQuery por job do Hadoop/Spark no tempo de efetivação.
Para mais informações, consulte as notas de alteração do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/53151b1ffaf22767ffb5e8db4f01624ba6a680c1/bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/CHANGES.txt">
        BigQuery
       </a>
       no repositório do GitHub.
      </li>
     </ul>
    </div>
    <h2 data-text="7 de novembro de 2016" id="november_7_2016">
     7 de novembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Suporte para a região
        <a href="https://www.blog.google/topics/google-cloud/google-cloud-platform-tokyo-region-now-open-for-business/">
         recém anunciada asia-northeast1
        </a>
       </strong>
       : o Cloud Dataproc está agora disponível na região recém-anunciada asia-northeast1.
      </li>
     </ul>
    </div>
    <h2 data-text="2 de novembro de 2016" id="november_2_2016">
     2 de novembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Rótulos de usuários [BETA]
       </strong>
       : atualmente, é possível aplicar rótulos
       <code>
        key=value
       </code>
       especificados pelo usuário a clusters e jobs do Cloud Dataproc. Dessa forma, você pode agrupar recursos e operações relacionadas para filtragem e listagem posterior. Como exemplo, você pode usar rótulos com clusters para distribuir o uso do Cloud Dataproc por grupos ou pessoas. Para mais informações, consulte a
       <a href="https://cloud.google.com/dataproc/docs/concepts/labels?hl=pt_br">
        documentação de rótulos de usuário
       </a>
       .
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Problemas corrigidos durante a atualização de cluster que provocavam falha nele. Agora, as falhas de atualização retornam o cluster para o estado
       <code>
        Running
       </code>
       .
      </li>
      <li>
       Problema corrigido no envio de um grande número de jobs rapidamente ou durante um longo período de tempo que provocava falha no cluster.
      </li>
      <li>
       Aumento do número máximo de jobs simultâneos por cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="18 de outubro de 2016" id="october_18_2016">
     18 de outubro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Atualização do Cloud Dataproc 1.1
       </strong>
       : a
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
        imagem do Cloud Dataproc 1.1
       </a>
       foi atualizada para incluir o
       <a href="https://spark.apache.org/releases/spark-release-2-0-1.html">
        Spark 2.0.1
       </a>
       e o
       <a href="https://hadoop.apache.org/docs/r2.7.3/">
        Hadoop 2.7.3
       </a>
       .
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Problema corrigido em que o HiveServer2 tinha a integridade afetada por até 60 segundos após a implantação do cluster. Agora, os jobs do Hive conectam-se com êxito ao HiveServer2 necessário logo após a implantação do cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="11 de outubro de 2016" id="october_11_2016">
     11 de outubro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Upgrade de conectores do Cloud Storage e do BigQuery
       </strong>
       : foram realizados os upgrades do conector do Cloud Storage para
       <code>
        gcs-connector-1.5.4
       </code>
       e do conector do BigQuery para
       <code>
        bigquery-connector-0.8.0
       </code>
       . Para ver mais informações, leia as observações de alteração do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/0e9d09a06ef2b191a8daa6620722b89f8d9081f2/gcs/CHANGES.txt">
        Cloud Storage
       </a>
       ou do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/0e9d09a06ef2b191a8daa6620722b89f8d9081f2/bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/CHANGES.txt">
        BigQuery
       </a>
       no repositório do GitHub.
      </li>
      <li>
       <strong>
        dataproc.localssd.mount.enable
       </strong>
       : foi adicionada a nova propriedade
       <code>
        dataproc.localssd.mount.enable
       </code>
       , configurável no momento da implantação do cluster, para fazer com que o Cloud Dataproc ignore os SSDs locais. Se definida, o Cloud Dataproc usará os discos permanentes principais do HDFS e os diretórios temporários do Hadoop para que os SSDs locais possam ser usados separadamente para finalidades definidas pelo usuário. Essa propriedade pode ser definida usando o argumento
       <code>
        --properties dataproc:dataproc.localssd.mount.enable=false
       </code>
       ao criar um cluster do Cloud Dataproc.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Problema corrigido em que a validação de cota da CPU das máquinas virtuais preemptivas estava sendo feita com a cota da CPU não preemptiva, mesmo quando a cota da CPU preemptiva estava definida.
      </li>
     </ul>
    </div>
    <h2 data-text="7 de outubro de 2016" id="october_7_2016">
     7 de outubro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       Console do Google Cloud Platform
       <ul>
        <li>
         Agora, é possível adicionar até oito
         <a href="https://cloud.google.com/compute/docs/disks/local-ssd?hl=pt_br">
          SSDs locais
         </a>
         aos worker nodes. O limite anterior era quatro.
        </li>
        <li>
         Ao consultar os detalhes do cluster, a página "Jobs" agora mostra os botões Parar e Excluir para cada job na lista. Antes, os botões só estavam visíveis na linha em que se passava o cursor do mouse.
        </li>
       </ul>
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Listagem otimizada de recursos por estado e UUID do cluster. Isso pode reduzir várias operações da lista de segundos para milissegundos.
      </li>
     </ul>
    </div>
    <h2 data-text="29 de setembro de 2016" id="september_29_2016">
     29 de setembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Modo de alta disponibilidade do Hadoop [BETA]
       </strong>
       : é possível criar clusters do Cloud Dataproc com o
       <em>
        modo de alta disponibilidade
       </em>
       ativado. Esse é um recurso opcional disponível ao criar um cluster. Nesse modo, os clusters do Cloud Dataproc têm três nós mestres, em vez de um. Assim, tanto a alta disponibilidade do HDFS quanto a do YARN possibilitam operações ininterruptas do YARN e do HDFS, mesmo em caso de falhas ou reinicializações de qualquer nó único.
       <p>
        Atualmente, esse recurso está disponível ao criar clusters com a ferramenta de linha de comando
        <code>
         <a href="https://cloud.google.com/dataproc/docs/gcloud-installation?hl=pt_br">
          gcloud
         </a>
        </code>
        ou a
        <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
         API REST do Cloud Dataproc
        </a>
        . Uma versão futura permitirá o suporte à criação de clusters com alta disponibilidade no
        <a href="https://console.developers.google.com?hl=pt_br">
         Console do Google Cloud Platform
        </a>
        .
       </p>
       <p>
        Consulte a
        <a href="https://cloud.google.com/dataproc/docs/concepts/high-availability?hl=pt_br">
         documentação do modo de alta disponibilidade
        </a>
        para saber mais informações.
       </p>
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Lista de jobs otimizada com base no estado ou no UUID do cluster. Isso pode reduzir significativamente o tempo necessário para listar os jobs.
      </li>
     </ul>
    </div>
    <h2 data-text="22 de setembro de 2016" id="september_22_2016">
     22 de setembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Upgrade de conectores do Cloud Storage e do BigQuery
       </strong>
       : foram realizados os upgrades do conector do Cloud Storage para
       <code>
        gcs-connector-1.5.3
       </code>
       e do conector do BigQuery para
       <code>
        bigquery-connector-0.7.9
       </code>
       . Para mais informações, consulte as
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop">
        notas de alteração
       </a>
       no repositório do GitHub.
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Como o Cloud Dataproc usa o Java 8 desde o lançamento da versão Beta em setembro de 2015, existe agora uma forte dependência no Java 8 ou superior.
      </li>
      <li>
       O comando
       <code>
        --preemptible-worker-boot-disk-size
       </code>
       não exige mais que você especifique
       <code>
        0
       </code>
       trabalho preemptivo se não quiser adicionar máquinas preemptivas ao criar um cluster.
      </li>
     </ul>
    </div>
    <h2 data-text="16 de setembro de 2016" id="september_16_2016">
     16 de setembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Tamanhos de disco de inicialização preemptivos
       </strong>
       : o tamanho do disco para workers preemptivos agora é configurado pela ferramenta de linha de comando
       <code>
        gcloud
       </code>
       na criação do cluster, mesmo quando os preemptivos não são adicionados a um cluster usando o comando
       <code>
        --preemptible-worker-boot-disk-size
       </code>
       .
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Ambiente convidado do Debian atualizado com as últimas alterações, conforme descrito na visão geral
       <a href="https://github.com/GoogleCloudPlatform/compute-image-packages#guest-overview">
        Ambiente convidado Linux para Google Compute Engine
       </a>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="1º de setembro de 2016" id="september_1_2016">
     1º de setembro de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Compatibilidade com o Gerenciamento de identidade e acesso [BETA]
       </strong>
       : o Cloud Dataproc atualmente tem compatibilidade
       <strong>
        beta
       </strong>
       com o
       <a href="https://cloud.google.com/iam?hl=pt_br">
        Gerenciamento de identidade e acesso (IAM, na sigla em inglês) do Google Cloud
       </a>
       . As permissões de IAM do Cloud Dataproc possibilitam que os usuários executem determinadas ações em clusters, jobs e operações do Cloud Dataproc. Consulte
       <a href="https://cloud.google.com/dataproc/docs/concepts/iam?hl=pt_br">
        Permissões do Cloud Dataproc e papéis de IAM
       </a>
       para mais informações.
      </li>
      <li>
       <strong>
        Suporte a LZO
       </strong>
       : agora, os clusters do Cloud Dataproc oferecem suporte nativo ao formato de compactação de dados LZO.
      </li>
      <li>
       <strong>
        Alternância de geração de registros do Google Stackdriver
       </strong>
       : agora, é possível desativar a geração de registros do Google Stackdriver nos clusters do Cloud Dataproc. Para isso, use o comando "--properties dataproc:dataproc.logging.stackdriver.enable=false" ao criar um cluster com a ferramenta de linha de comando "gcloud".
      </li>
     </ul>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <ul>
      <li>
       Agora, as definições de recursos dos clusters recém-implantados exibem uma versão de imagem submenor totalmente resolvida (ex.
       <code>
        1.0.11
       </code>
       em vez de
       <code>
        1.0
       </code>
       ). Isso facilita reverter temporariamente para uma versão submenor mais antiga. Consulte
       <a href="https://cloud.google.com/dataproc/docs/concepts/versioning?hl=pt_br">
        Controle de versões do Cloud Dataproc
       </a>
       para mais informações.
      </li>
      <li>
       A mensagem exibida depois do envio de uma operação de longa duração no Console do Google Cloud Platform, como criar ou excluir um cluster, indicará agora que a operação foi "enviada" em vez de ter "conseguido".
      </li>
     </ul>
    </div>
    <h2 data-text="25 de agosto de 2016" id="august_25_2016">
     25 de agosto de 2016
    </h2>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <b>
      Padrão do Cloud Dataproc 1.1
     </b>
     : o
     <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
      <code>
       Cloud Dataproc 1.1
      </code>
     </a>
     passa a ser a versão de imagem padrão para novos clusters.
    </div>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <ul>
      <li>
       <strong>
        Upgrade de conectores do Cloud Storage e do BigQuery
       </strong>
       : foram feitos os upgrades do conector do Cloud Storage para
       <code>
        gcs-connector-1.5.2
       </code>
       e o do conector do BigQuery para
       <code>
        bigquery-connector-0.7.8
       </code>
       , otimizando o desempenho. Consulte as notas da versão do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/8de83da3f65f3e629b9e6120d7db7b644e871704/gcs/CHANGES.txt">
        gcs-connector
       </a>
       e do
       <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/8de83da3f65f3e629b9e6120d7db7b644e871704/bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/CHANGES.txt">
        bigquery-connector
       </a>
       para saber mais informações.
      </li>
      <li>
       <b>
        Apache Zeppelin 0.6.1
       </b>
       : foi realizado o upgrade do
       <a href="http://zeppelin.apache.org">
        Apache Zeppelin
       </a>
       , criado para o Cloud Dataproc e instalável com
       <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/zeppelin">
        esta ação de inicialização
       </a>
       para a versão
       <code>
        0.6.1
       </code>
       . Essa nova versão do Zeppelin é compatível com o Google BigQuery.
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <ul>
      <li>
       Problema corrigido em que a adição de muitos nodes (mais de 200) a um cluster provocava falha em alguns deles.
      </li>
      <li>
       Problema corrigido em que a saída das ações de inicialização que esgotavam o tempo limite não era copiada para o Cloud Storage.
      </li>
     </ul>
    </div>
    <h2 data-text="16 de agosto de 2016" id="august_16_2016">
     16 de agosto de 2016
    </h2>
    <div class="release-deprecated">
     <strong>
      DEPRECATED:
     </strong>
     As duas
     <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
      versões de imagens
     </a>
     do Cloud Dataproc, lançadas durante o Cloud Dataproc beta
     <code>
      0.1
     </code>
     e
     <code>
      0.2
     </code>
     , não receberão mais atualizações. Você pode continuar usando as imagens Beta, mas nenhuma atualização nova, como correções de bugs e atualizações de conectores, será aplicada a essas duas versões de imagem com uso suspenso.
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     As versões de imagens lançadas após a disponibilização do Cloud Dataproc, a partir de
     <code>
      1.0
     </code>
     , estarão sujeitas à
     <a href="https://cloud.google.com/dataproc/docs/concepts/versioning?hl=pt_br">
      política de controle de versões do Cloud Dataproc
     </a>
     .
    </div>
    <h2 data-text="8 de agosto de 2016" id="august_8_2016">
     8 de agosto de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <strong>
      Cloud Dataproc 1.1
     </strong>
     : foi lançada uma nova
     <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
      versão de imagens
     </a>
     ,
     <code>
      Cloud Dataproc 1.1
     </code>
     . Vários componentes foram atualizados para essa versão de imagem, incluindo:
     <ul>
      <li>
       <a href="http://spark.apache.org">
        Apache Spark
       </a>
       <code>
        2.0.0
       </code>
      </li>
      <li>
       <a href="http://hive.apache.org">
        Apache Hive
       </a>
       <code>
        2.1.0
       </code>
      </li>
      <li>
       <a href="http://pig.apache.org">
        Apache Pig
       </a>
       <code>
        0.16.0
       </code>
      </li>
     </ul>
     <p>
      Para criar um cluster com a imagem
      <code>
       1.1
      </code>
      , use a ferramenta de linha de comando
      <code>
       gcloud
      </code>
      com o argumento
      <code>
       --image-version
      </code>
      , como
      <code>
       gcloud dataproc clusters create --image-version 1.1
      </code>
      .
     </p>
    </div>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <strong>
      SDK do Cloud versão 121.0.0
     </strong>
     : diversos argumentos
     <code>
      gcloud dataproc
     </code>
     foram atualizados.
     <ul>
      <li>
       O argumento
       <code>
        --preemptible-worker-boot-disk-size
       </code>
       foi promovido para disponibilidade geral e pode ser usado para ajustar o tamanho do disco permanente (em GB) dos trabalhos preemptivos.
      </li>
      <li>
       Os argumentos
       <code>
        --master-boot-disk-size-gb
       </code>
       e
       <code>
        --worker-boot-disk-size-gb
       </code>
       foram removidos. Em vez deles, use
       <code>
        --master-boot-disk-size
       </code>
       e
       <code>
        --worker-boot-disk-size
       </code>
       .
      </li>
     </ul>
    </div>
    <h2 data-text="2 de agosto de 2016" id="august_2_2016">
     2 de agosto de 2016
    </h2>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <strong>
      Upgrade de conectores do Cloud Storage e do BigQuery
     </strong>
     : foram realizados os upgrades do conector do Cloud Storage para
     <code>
      gcs-connector-1.5.1
     </code>
     e do conector do BigQuery para
     <code>
      bigquery-connector-0.7.7
     </code>
     .
Consulte as notas da versão do
     <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/8de83da3f65f3e629b9e6120d7db7b644e871704/gcs/CHANGES.txt">
      gcs-connector
     </a>
     e do
     <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/8de83da3f65f3e629b9e6120d7db7b644e871704/bigquery/src/main/java/com/google/cloud/hadoop/io/bigquery/CHANGES.txt">
      bigquery-connector
     </a>
     para saber mais informações.
    </div>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <strong>
      Imagem de visualização atualizada
     </strong>
     : diversos componentes da
     <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#other_versions">
      imagem de visualização
     </a>
     foram atualizados:
     <ul>
      <li>
       <a href="http://spark.apache.org">
        Apache Spark
       </a>
       <code>
        2.0.0
       </code>
      </li>
      <li>
       <a href="http://hive.apache.org">
        Apache Hive
       </a>
       <code>
        2.1.0
       </code>
      </li>
      <li>
       <a href="http://pig.apache.org">
        Apache Pig
       </a>
       <code>
        0.16.0
       </code>
      </li>
     </ul>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     Problema corrigido em que o cache de consistência do Cloud Storage com base em NFS não era limpo nos clusters de longa execução com altas taxas de criação de arquivo em período prolongado (mais de 1 milhão de arquivos por hora durante um longo período).
    </div>
    <h2 data-text="19 de julho de 2016" id="july_19_2016">
     19 de julho de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Suporte para a nova região
       <code>
        us-west1
       </code>
      </strong>
      : o Cloud Dataproc está disponível desde o primeiro dia na
      <a href="https://cloudplatform.googleblog.com/2016/07/the-latest-for-Cloud-customers-machine-learning-and-west-coast-expansion.html">
       recém-anunciada região west-1
      </a>
      .
Conforme mencionado no aviso, parte da latência de alguns usuários da Costa Oeste dos EUA pode ser reduzida.
     </li>
     <li>
      <strong>
       Upgrade do Apache Spark para 1.6.2
      </strong>
      : Apache Spark na
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
       versão da imagem do Cloud Dataproc
      </a>
      <code>
       1.0
      </code>
      foi atualizado de
      <code>
       1.6.1
      </code>
      para
      <code>
       1.6.2
      </code>
      .
     </li>
     <li>
      <strong>
       Upgrades dos conectores do Cloud Storage e do BigQuery
      </strong>
      : o conector do Cloud Storage foi atualizado para
      <code>
       gcs-connector-1.5.0
      </code>
      e o conector do BigQuery foi atualizado para
      <code>
       bigquery-connector-0.7.6
      </code>
      . Essas novas versões apresentam vários recursos inéditos e correções.
      <ul>
       <li>
        <strong>
         Fluxos de saída anexáveis
        </strong>
        : o GHFS (Google Hadoop File System) agora tem uma opção para ativar o suporte a fluxos de saída anexáveis. Ative essa opção definindo a propriedade
        <code>
         fs.gs.outputstream.type
        </code>
        como
        <code>
         SYNCABLE_COMPOSITE
        </code>
        .
       </li>
       <li>
        <strong>
         Repete automaticamente em caso de erros 429
        </strong>
        : agora, os erros HTTP 429 (limite de taxa) das APIs do Google serão automaticamente repetidos com uma retirada.
       </li>
       <li>
        <strong>
         Desempenho do Cloud Storage
        </strong>
        : desempenho de leitura do conector do Cloud Storage aprimorado, principalmente para várias leituras breves ou muitas buscas.
Consulte o
        <a href="https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/CHANGES.txt">
         registro detalhado de alterações
        </a>
        para saber mais informações.
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes">
     Correções de bugs
    </h4>
    <ul>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        O Console do Google Cloud Platform agora usa o Cloud Dataproc
        <code>
         v1
        </code>
        em vez da API
        <code>
         v1beta1
        </code>
        . O clique no link
        <code>
         equivalent REST
        </code>
        mostra os caminhos da API
        <code>
         v1
        </code>
        apropriados e os nomes dos recursos.
       </li>
      </ul>
     </li>
     <li>
      Correção do problema em que alguns nós HDFS não ingressavam no cluster porque o nome de domínio deles não foi resolvido na primeira inicialização.
     </li>
    </ul>
    <h2 data-text="1º de julho de 2016" id="july_1_2016">
     1º de julho de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_2">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Ferramenta de linha de comando
       <code>
        gcloud
       </code>
      </strong>
      <ul>
       <li>
        Adicionada a sinalização
        <code>
         --preemptible-worker-boot-disk-size
        </code>
        , que pode ser usada para ajustar o tamanho do disco de trabalhos preemptivos. Ela foi adicionada ao rastreamento
        <code>
         gcloud beta
        </code>
        .
       </li>
       <li>
        Agora, a sinalização
        <code>
         --*-boot-disk-size-gb
        </code>
        está com o uso suspenso em todos os rastreamentos e foi substituída pelos comandos
        <code>
         --*-boot-disk-size
        </code>
        .
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_2">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Corrigido um bug na versão de junho. Ele provocava falha nos clusters somente após aguardar durante cerca de 30 minutos. Isso ocorria com mais frequência quando havia falha nas ações de inicialização durante a criação do cluster. Agora, pode haver falha nos clusters em um minuto a partir da falha de uma ação de inicialização.
     </li>
     <li>
      Redução no tempo de inicialização dos jobs do SparkSQL com diretórios particionados/aninhados ao aplicar um patch ao Spark (
      <a href="https://issues.apache.org/jira/browse/SPARK-9926">
       SPARK-9926
      </a>
      ).
     </li>
     <li>
      Otimização do tempo de inicialização para qualquer job com muitas entradas de arquivo ao aplicar um patch ao Hadoop (
      <a href="https://issues.apache.org/jira/browse/HADOOP-12810">
       HADOOP-12810
      </a>
      ).
     </li>
    </ul>
    <h2 data-text="10 de junho de 2016" id="june_10_2016">
     10 de junho de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_3">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Visualização do Spark 2.0
      </strong>
      : a
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#other_versions">
       imagem de visualização
      </a>
      já inclui a versão de visualização do
      <a href="http://spark.apache.org">
       Apache Spark
      </a>
      .
     </li>
    </ul>
    <h2 data-text="4 de maio de 2016" id="may_4_2016">
     4 de maio de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_4">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Ação de inicialização do Cloud SQL
      </strong>
      : o Cloud Dataproc já tem uma ação de inicialização
      <a href="https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/cloud-sql-proxy">
       E/S do Cloud SQL e Hive Metastore
      </a>
      . Essa ação instala um
      <a href="https://cloud.google.com/sql/docs/sql-proxy?hl=pt_br">
       proxy do Google Cloud SQL
      </a>
      em cada nó em um cluster do Cloud Dataproc.
Ela também configura o cluster para armazenar os metadados do Apache Hive em uma determinada instância do Cloud SQL.
     </li>
    </ul>
    <h2 data-text="29 de abril de 2016" id="april_29_2016">
     29 de abril de 2016
    </h2>
    <h4 data-text="Correções de bugs" id="bugfixes_3">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Agora, o diretório de teste de um job do Cloud Dataproc é limpo automaticamente quando o job é concluído.
     </li>
     <li>
      Se não for possível excluir o cluster adequadamente, agora ele será alterado para o estado
      <code>
       FAILED
      </code>
      , em vez de permanecer no estado
      <code>
       DELETING
      </code>
      .
     </li>
     <li>
      Correção de um problema que impedia
      <a href="https://cloud.google.com/dataproc/docs/concepts/cluster-properties?hl=pt_br">
       <code>
        --properties
command
       </code>
      </a>
      do Cloud Dataproc de alterar as propriedades do MapReduce.
     </li>
     <li>
      Correção do bug em que uma exceção era gerada ao tentar definir a agregação de registros do YARN como saída para o Cloud Storage (em relação ao
      <a href="https://issues.apache.org/jira/browse/YARN-3269">
       YARN-3269
      </a>
      ).
     </li>
    </ul>
    <h2 data-text="30 de março de 2016" id="march_30_2016">
     30 de março de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_5">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Spark 1.6.1
      </strong>
      : a versão da imagem do Cloud Dataproc
      <code>
       1.0
      </code>
      foi atualizada para incluir a versão de manutenção do
      <a href="https://spark.apache.org/news/spark-1-6-1-released.html">
       Spark 1.6.1
      </a>
      , em vez do Spark 1.6.0.
     </li>
     <li>
      <strong>
       Upgrades OSS
      </strong>
      : esta versão atualiza os
      <a href="https://github.com/GoogleCloudPlatform/bigdata-interop">
       conectores
      </a>
      do Cloud Storage e do Google BigQuery para gcs-connector-1.4.5 e bigquery-connector-0.7.5, respectivamente.
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_4">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Agora, é possível especificar
      <code>
       --num-preemptible-workers 0
      </code>
      por meio da ferramenta de linha de comando
      <code>
       gcloud
      </code>
      . Antes, isso provocava falha.
     </li>
     <li>
      Correção de um problema de validação, que gerava erros HTTP
      <code>
       500
      </code>
      quando a resposta tinha que ser
      <code>
       400 bad input
      </code>
      ou
      <code>
       200 OK
      </code>
      .
     </li>
     <li>
      Resolvido um problema de validação de cache e inferência reativada do diretório de reativação no conector do Cloud Storage (
      <code>
       fs.gs.implicit.dir.infer.enable
      </code>
      ).
     </li>
     <li>
      Ajuste das configurações de migração do Google Compute Engine por causa de falhas inesperadas no host. As VMs normais serão automaticamente reiniciadas após a migração, e as máquinas preemptivas não. Antes, todas as VMs eram definidas para não serem reiniciadas automaticamente após a migração.
     </li>
     <li>
      Resolução de um problema em que o envio de job rápido resultaria em um erro
      <code>
       Too many
pending operations on a resource
      </code>
      .
     </li>
    </ul>
    <h2 data-text="8 de março de 2016" id="march_8_2016">
     8 de março de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_6">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Suporte de sub-rede
      </strong>
      : o Cloud Dataproc agora aceita
      <a href="https://cloud.google.com/compute/docs/subnetworks?hl=pt_br">
       sub-redes
      </a>
      por meio da ferramenta de linha de comando
      <code>
       gcloud
      </code>
      . Use agora o comando
      <code>
       --subnet SUBNET
      </code>
      para especificar uma sub-rede ao criar um cluster do Cloud Dataproc.
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_5">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Adição de validação rigorosa dos URIs completos dos recursos de computação. Os seguintes padrões são permitidos:
      <ul>
       <li>
        <code>
         https://&lt;authority&gt;/compute/&lt;version&gt;/projects/...
        </code>
       </li>
       <li>
        <code>
         compute/&lt;version&gt;/projects/...
        </code>
       </li>
       <li>
        <code>
         projects/...
        </code>
       </li>
      </ul>
     </li>
     <li>
      Correção do problema em que a cota de disco não era verificada quando aumentava o tamanho do cluster.
     </li>
    </ul>
    <h2 data-text="22 de fevereiro de 2016" id="february_22_2016">
     22 de fevereiro de 2016
    </h2>
    <p>
     <strong>
      Agora, o Cloud Dataproc está com disponibilidade geral.
     </strong>
     Para mais informações, consulte nossa
     <a href="">
      postagem do blog de anúncio
     </a>
    </p>
    <h4 data-text="Novos recursos" id="new_features_7">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Tipos de máquina do Compute Engine personalizados
      </strong>
      : os clusters do Cloud Dataproc agora aceitam
      <a href="https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type?hl=pt_br">
       tipos de máquina do Compute Engine
      </a>
      para nós mestre e de trabalho. Isso significa ser possível criar clusters com quantidades personalizadas de memória e CPUs virtuais. Para saber mais informações, leia a
      <a href="https://cloud.google.com/dataproc/docs/concepts/custom-machine-types?hl=pt_br">
       documentação do Dataproc sobre tipos de máquina personalizados
      </a>
      .
     </li>
     <li>
      <strong>
       Upgrades OSS
      </strong>
      : liberamos o
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
       Cloud Dataproc versão 1.0
      </a>
      .
Essa versão inclui um upgrade para o Apache Spark
      <code>
       1.6.0
      </code>
      e o Apache Hadoop
      <code>
       2.7.2
      </code>
      . Ela também inclui novas versões dos
      <a href="https://github.com/GoogleCloudPlatform/bigdata-interop">
       conectores
      </a>
      do Cloud Storage e do Google BigQuery.
     </li>
     <li>
      <strong>
       API v1
      </strong>
      : a API
      <code>
       v1
      </code>
      do Cloud Dataproc agora está ativa. Ela inclui suporte à regionalidade com correções e ajustes secundários. Ela está disponível no
      <a href="https://developers.google.com/apis-explorer/?hl=pt_br#p/dataproc/v1/">
       APIs Explorer
      </a>
      e tem também um
      <a href="http://search.maven.org/#artifactdetails%7Ccom.google.apis%7Cgoogle-api-services-dataproc%7Cv1-rev3-1.21.0%7Cjar">
       artefato do Maven
      </a>
      no Maven Central. Para ver mais informações, consulte a
      <a href="https://cloud.google.com/dataproc/docs/reference/rest?hl=pt_br">
       documentação da API REST
      </a>
      .
     </li>
     <li>
      <strong>
       Suporte para --jars do PySpark
      </strong>
      : adição de suporte para uso da opção
      <code>
       --jars
      </code>
      em jobs do PySpark.
     </li>
     <li>
      <strong>
       Ativação automática da API
      </strong>
      : a ativação da API Cloud Dataproc agora ativa automaticamente as APIs dependentes necessárias, como do Cloud Storage e do Google Compute Engine.
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_6">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Resolução de vários problemas que travavam de vez em quando o processo de redução de alguns clusters.
     </li>
     <li>
      Aprimoramento da validação de alguns tipos de URLs inválidos, que antes falhavam durante a implantação do cluster.
     </li>
    </ul>
    <h2 data-text="3 de fevereiro de 2016" id="february_3_2016">
     3 de fevereiro de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_8">
     Novos recursos
    </h4>
    <ul>
     <li>
      Uma nova opção
      <code>
       --image-version
      </code>
      foi adicionada:
      <code>
       preview
      </code>
      <ul>
       <li>
        Diferentemente de outras versões numéricas, como
        <code>
         0.1
        </code>
        e
        <code>
         0.2
        </code>
        , a versão
        <code>
         preview
        </code>
        incluirá os componentes mais recentes do Hadoop, Spark, Pig e Hive, previstos para possível lançamento na próxima versão de distribuição estável do Cloud Dataproc, e será alterada ao longo do tempo.
       </li>
       <li>
        A partir de 3 de fevereiro de 2016, a versão
        <code>
         preview
        </code>
        contém o Spark 1.6.0, com as mesmas versões do Hadoop, Pig e Hive que o Cloud Dataproc
        <code>
         0.2
        </code>
        .
       </li>
       <li>
        A opção
        <code>
         preview
        </code>
        está sendo implantada no
        <strong>
         Console do Google Cloud Platform
        </strong>
        . Dessa maneira, ela não pode estar visível na conta para outra semana.
Para todos os usuários, a opção
        <code>
         preview
        </code>
        pode ser acessada implantando os clusters com a ferramenta de linha de comando
        <code>
         gcloud
        </code>
        .
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_7">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Maior confiabilidade do comando
      <code>
       DeleteJob
      </code>
      .
     </li>
     <li>
      Correção do bug que fazia com que os jobs permanecessem no estado
      <code>
       RUNNING
      </code>
      depois de serem concluídos com êxito.
     </li>
    </ul>
    <h2 data-text="27 de janeiro de 2016" id="january_27_2016">
     27 de janeiro de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_9">
     Novos recursos
    </h4>
    <ul>
     <li>
      Duas novas opções foram adicionadas à ferramenta de linha de comando
      <code>
       gcloud
      </code>
      do Cloud Dataproc para incluir tags e metadados às máquinas virtuais usadas nos clusters do Cloud Dataproc. Essas tags e os metadados serão aplicados às instâncias regulares e preemptivas.
      <ul>
       <li>
        A opção
        <code>
         --tags
        </code>
        adicionará tags às instâncias do Google Compute Engine em um cluster. Por exemplo, ao usar o argumento
        <code>
         --tags foo,bar,baz
        </code>
        , três tags serão adicionadas às instâncias de máquina virtual no cluster.
       </li>
       <li>
        A opção
        <code>
         --metadata
        </code>
        adicionará metadados às instâncias do Google Compute Engine. Por exemplo, ao usar
        <code>
         --metadata 'meta1=value1,key1=value2'
        </code>
        , dois pares de chave-valor de metadados serão adicionados.
       </li>
      </ul>
     </li>
     <li>
      Suporte a clusters heterogêneos, em que o nó mestre e os nós de trabalho têm quantidades de memória diferentes. Algumas configurações de memória se baseavam no nó mestre, o que causava alguns problemas, conforme descrito nesta
      <a href="http://stackoverflow.com/questions/33599308/incorrect-memory-allocation-for-yarn-spark-after-automatic-setup-of-dataproc-clu" title="Pergunta sobre o Stack Overflow">
       pergunta sobre o Stack Overflow
      </a>
      .
Agora, o Cloud Dataproc é mais compatível com clusters que têm nós mestre e de trabalho.
     </li>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        A guia
        <strong>
         Saída
        </strong>
        de um job agora inclui a opção
        <code>
         Line wrapping
        </code>
        para facilitar a visualização da saída do job com linhas muito longas.
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_8">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Correção de dois problemas que, às vezes, faziam com que as máquinas virtuais permanecessem ativas após o envio de uma solicitação de exclusão do cluster.
     </li>
     <li>
      A configuração
      <code>
       maxExecutors
      </code>
      do Spark agora está definida como
      <code>
       10000
      </code>
      para evitar falha do AppMaster em jobs com muitas tarefas.
     </li>
     <li>
      Processamento aprimorado para envio de jobs agressivos por meio de várias alterações no agente do Cloud Dataproc, inclusive:
      <ul>
       <li>
        limitação do número de jobs simultâneos de maneira proporcional à memória do nó mestre;
       </li>
       <li>
        verificação da memória livre antes de programar novos jobs;
       </li>
       <li>
        taxa de limitação da quantidade de jobs que podem ser programados por ciclo.
       </li>
      </ul>
     </li>
     <li>
      Melhoria no cálculo da capacidade do HDFS antes da ativação ou desativação dos nós para impedir atualizações excessivamente longas.
     </li>
    </ul>
    <h2 data-text="21 de janeiro de 2016" id="january_21_2016">
     21 de janeiro de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_10">
     Novos recursos
    </h4>
    <ul>
     <li>
      Agora, o comando dataproc no SDK do Google Cloud inclui a opção
      <code>
       --properties
      </code>
      para adicionar ou atualizar propriedades em alguns arquivos de configuração do cluster, como
      <code>
       core-site.xml
      </code>
      . As propriedades são mapeadas para esses arquivos especificando um prefixo, como
      <code>
       core:io.serializations
      </code>
      . Esse comando possibilita modificar várias propriedades e arquivos ao criar um cluster.
Para saber mais informações, consulte a
      <a href="https://cloud.google.com/dataproc/docs/concepts/cluster-properties?hl=pt_br" title="Documentação de propriedades do Cloud Dataproc">
       documentação do Cloud Dataproc do comando
       <code>
        --properties
       </code>
      </a>
      .
     </li>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        Uma opção foi adicionada ao formulário “Criar clusters” para ativar o escopo da plataforma de nuvem de um cluster. Isso permite ver e gerenciar os dados em todos os serviços do Google Cloud Platform dos clusters do Cloud Dataproc.
Para encontrar essa opção, expanda a seção
        <code>
         Preemptible workers, bucket,
network, version, initialization, &amp; access options
        </code>
        na parte inferior do formulário.
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_9">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Os jobs do SparkR não falham mais imediatamente com o erro “permissão negada” (
      <a href="https://issues.apache.org/jira/browse/SPARK-11304">
       Problema no JIRA do Spark
      </a>
      ).
     </li>
     <li>
      A configuração de geração de registros de jobs do Spark com a opção
      <code>
       --driver-logging-levels
      </code>
      não interfere mais nas opções de driver do Java.
     </li>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        O erro mostrado para ações de inicialização formatadas incorretamente agora aparece de maneira adequada com as informações sobre o problema.
       </li>
       <li>
        Agora, as mensagens de erro muito extensas incluem uma barra de rolagem para que o botão Fechar permaneça na tela. Referente às correções de bugs de ## 7 de janeiro de 2016 ####.
       </li>
      </ul>
     </li>
     <li>
      Correção do problema na versão do Dataproc
      <code>
       0.1
      </code>
      que fazia com que os arquivos
      <code>
       _SUCCESS
      </code>
      e
      <code>
       _FAILURE
      </code>
      de zero byte de cada job fossem continuamente regravados no Cloud Storage.
     </li>
    </ul>
    <h2 data-text="16 de dezembro de 2016" id="december_16_2016_2">
     16 de dezembro de 2016
    </h2>
    <h4 data-text="Novos recursos" id="new_features_11">
     Novos recursos
    </h4>
    <ul>
     <li>
      Agora, os clusters do Cloud Dataproc têm
      <code>
       vim
      </code>
      ,
      <code>
       git
      </code>
      e
      <code>
       bash-completion
      </code>
      instalados por padrão.
     </li>
     <li>
      A API Cloud Dataproc tem um
      <a href="http://mvnrepository.com/artifact/com.google.apis/google-api-services-dataproc/v1beta1-rev1-1.21.0">
       artefato do Maven
      </a>
      oficial,
      <a href="http://google-api-client-libraries.appspot.com/documentation/dataproc/v1beta1/java/latest/?hl=pt_br">
       Javadocs
      </a>
      e um arquivo
      <a href="https://developers.google.com/api-client-library/java/apis/dataproc/v1?hl=pt_br">
       .zip para download
      </a>
      .
     </li>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        Agora, é possível especificar propriedades ao enviar um job e vê-las na guia
        <em>
         Configuração
        </em>
        correspondente.
       </li>
       <li>
        O botão
        <code>
         Clone
        </code>
        foi adicionado para permitir que você copie facilmente todas as informações sobre um job para o novo formulário de envio dele.
       </li>
       <li>
        Os ícones da lateral esquerda de clusters e jobs agora são personalizados, e não genéricos.
       </li>
       <li>
        Na parte inferior do formulário de criação de cluster, o campo
        <code>
         Image version
        </code>
        foi adicionado para que você selecione uma
        <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br" title="Versões do Cloud Dataproc">
         versão de imagem do Cloud Dataproc específica
        </a>
        .
       </li>
       <li>
        A guia
        <code>
         VM Instances
        </code>
        foi adicionada à página de detalhes do cluster, usada para exibir uma lista de todas as VMs no cluster e utilizar o SSH com facilidade no nó mestre.
       </li>
       <li>
        Na parte inferior do formulário de criação de cluster, o campo
        <code>
         Initialization Actions
        </code>
        foi adicionado para que você especifique
        <a href="https://cloud.google.com/dataproc/docs/concepts/init-actions?hl=pt_br">
         ações de inicialização
        </a>
        .
       </li>
       <li>
        Os caminhos para os intervalos do
        <a href="https://cloud.google.com/storage?hl=pt_br" title="Cloud Storage">
         Cloud Storage
        </a>
        que são exibidos nas mensagens de erro agora são links clicáveis.
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_10">
     Correções de bugs
    </h4>
    <ul>
     <li>
      As configurações
      <code>
       distcp
      </code>
      são forçadas a corresponder às configurações
      <code>
       mapred-site.xml
      </code>
      e a fornecer outras correções para o comando
      <code>
       distcp
      </code>
      . Consulte
      <a href="https://issues.apache.org/jira/browse/MAPREDUCE-5653">
       este JIRA relacionado
      </a>
      .
     </li>
     <li>
      Garantia de que os trabalhos criados durante uma atualização não ingressem no cluster antes do término das ações de inicialização personalizadas.
     </li>
     <li>
      Garantia de que os trabalhos sempre se desconectem do cluster quando o agente do Cloud Dataproc é encerrado.
     </li>
     <li>
      Correção da condição de corrida no front-end da API que ocorria durante a validação de uma solicitação e a marcação do cluster como em atualização.
     </li>
     <li>
      Aprimoramento de verificações de validação para cota, imagem do Cloud Dataproc e ações de inicialização ao atualizar clusters.
     </li>
     <li>
      Tratamento aprimorado de jobs quando o agente do Cloud Dataproc é reiniciado.
     </li>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        Permissão de argumentos duplicados ao enviar um job.
       </li>
       <li>
        Substituição da mensagem genérica
        <code>
         Failed to load
        </code>
        por detalhes sobre a causa do erro quando ele não é relacionado ao Cloud Dataproc.
       </li>
       <li>
        Quando um único arquivo jar de um job é enviado, ele pode ser listado somente no campo
        <code>
         Main class or jar
        </code>
        no formulário
        <strong>
         Enviar um job
        </strong>
        . Não é mais preciso listá-lo no campo
        <code>
         Jar files
        </code>
        .
       </li>
      </ul>
     </li>
    </ul>
    <h2 data-text="18 de novembro de 2015" id="november_18_2015">
     18 de novembro de 2015
    </h2>
    <p>
     <em>
      As implantações estão programadas para ocorrer em quatro dias e ser implantadas ou disponibilizadas para uso nos clusters do Cloud Dataproc no fim do quarto dia, a partir da data de lançamento anunciada da versão.
     </em>
    </p>
    <h4 data-text="Novos recursos" id="new_features">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Seleção de versões
      </strong>
      : com o lançamento do
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
       Cloud Dataproc versão 0.2
      </a>
      , agora é possível selecionar versões diferentes do Cloud Dataproc. Consulte
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning?hl=pt_br">
       Controle de versões do Cloud Dataproc
      </a>
      para ver mais informações sobre compatibilidade com versões anteriores, bem como a
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br">
       Lista das versões do Cloud Dataproc
      </a>
      para conhecer os componentes de software compatíveis com cada versão. Selecione uma versão do Cloud Dataproc ao criar um cluster por meio da API Cloud Dataproc, do SDK do Cloud (usando o comando
      <code>
       gcloud beta dataproc clusters create --image-version
      </code>
      ), ou pelo
      <a href="https://console.cloud.google.com/?hl=pt_br" target="console">
       Console do Google Cloud Platform
      </a>
      . Dentro de quatro dias do lançamento da nova versão em uma região, ela se tornará a versão padrão usada para criar novos clusters na região.
     </li>
     <li>
      <strong>
       Upgrades OSS
      </strong>
      : liberamos o
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
       Cloud Dataproc versão 0.2
      </a>
      .
O novo componente do Spark inclui várias correções de bugs. O novo componente do Hive possibilita usar o comando
      <code>
       hive
      </code>
      , apresenta melhorias no desempenho e tem um novo metastore.
     </li>
     <li>
      <strong>
       Atualizações de conectores
      </strong>
      : lançamos atualizações para os
      <a href="https://github.com/GoogleCloudPlatform/bigdata-interop">
       conectores do BigQuery e do Google Cloud Storage
      </a>
      , 0.7.3 e 1.4.3, respectivamente. Esses conectores corrigem diversos bugs, e as novas versões agora estão incluídas no
      <a href="https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions?hl=pt_br#supported_cloud_dataproc_versions">
       Cloud Dataproc versão 0.2
      </a>
      .
     </li>
     <li>
      <strong>
       Metastore do Hive
      </strong>
      : incluímos o metastore permanente por cluster com base em MySQL, compartilhado entre o Hive e o SparkSQL. Ele também corrige o comando
      <code>
       hive
      </code>
      .
     </li>
     <li>
      <strong>
       Mais bibliotecas nativas
      </strong>
      : agora, o Cloud Dataproc inclui bibliotecas nativas do Snappy. Ele também inclui as bibliotecas nativas BLAS, LAPACK e ARPACK no MLlib do Spark.
     </li>
     <li>
      <strong>
       Comando
       <code>
        --diagnose
       </code>
       de clusters
      </strong>
      : o SDK do Cloud agora inclui um comando
      <a href="https://cloud.google.com/dataproc/docs/support/diagnose-command?hl=pt_br">
       --diagnose
      </a>
      para reunir informações de registro e de diagnóstico sobre o cluster. Veja mais detalhes sobre esse comando na
      <a href="https://cloud.google.com/dataproc/docs/support/diagnose-command?hl=pt_br">
       documentação de suporte do Cloud Dataproc
      </a>
      .
     </li>
    </ul>
    <h4 data-text="Correções de bugs" id="bugfixes_11">
     Correções de bugs
    </h4>
    <ul>
     <li>
      Correção da capacidade para excluir jobs com falha rápida antes da criação de alguns diretórios de cluster e de teste.
     </li>
     <li>
      Correção de alguns erros restantes com as configurações vmem ao usar o comando
      <code>
       distcp
      </code>
      .
     </li>
     <li>
      Correção de um bug raro em que problemas subjacentes do Google Compute Engine provocavam falha na exclusão das instâncias de VM depois que o cluster do Cloud Dataproc era excluído com êxito.
     </li>
     <li>
      Correção do comando
      <code>
       Hive
      </code>
      .
     </li>
     <li>
      Correção de relatório de erros ao atualizar o número de trabalhos (padrão e preemptivos) no cluster.
     </li>
     <li>
      Correção de alguns casos de erros
      <code>
       Rate Limit Exceeded
      </code>
      .
     </li>
     <li>
      O comprimento máximo do nome do cluster agora é o correto de 55 caracteres, em vez de 56.
     </li>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        Agora, a lista de clusters inclui a coluna
        <code>
         Created
        </code>
        , e a guia de configuração do cluster inclui o campo
        <code>
         Created
        </code>
        , que informa o tempo de criação dele.
       </li>
       <li>
        Na tela de criação do cluster, tamanhos de memória maiores que 999 GB agora são exibidos em TB.
       </li>
       <li>
        Os campos que estavam faltando na guia de configuração de job do PySpark e do Hive (
        <code>
         Additional Python Files
        </code>
        e
        <code>
         Jar Files
        </code>
        ) foram adicionados.
       </li>
       <li>
        A opção para adicionar nós preemptivos ao criar um cluster agora está no “extensor” na parte inferior do formulário.
       </li>
       <li>
        Tipos de máquina com memória insuficiente (menos de 3,5 GB) não são mais exibidos na lista (antes, a seleção de um desses tipos de máquinas pequenos gerava um erro de back-end).
       </li>
       <li>
        O texto de marcador no campo Argumentos do formulário de envio de job foi corrigido.
       </li>
      </ul>
     </li>
    </ul>
    <h4 data-text="Principais melhorias nos serviços" id="core_service_improvements">
     Principais melhorias nos serviços
    </h4>
    <ul>
     <li>
      Se definida, a configuração da zona padrão de um projeto agora é usada como o valor padrão para a zona no formulário de criação de cluster no Console do GCP.
     </li>
    </ul>
    <h4 data-text="Otimizações" id="optimizations">
     Otimizações
    </h4>
    <ul>
     <li>
      O desempenho do Hive foi substancialmente melhorado, em especial nas tabelas particionadas com grande número de partições.
     </li>
     <li>
      Agora, o listStatus multissegmentado foi ativado, o que pode acelerar o tempo de inicialização do job no FileInputFormats que lê grandes números de arquivos e diretórios no Cloud Storage.
     </li>
    </ul>
    <h2 data-text="23 de outubro de 2015" id="october_23_2015">
     23 de outubro de 2015
    </h2>
    <h4 data-text="Novos recursos" id="new_features_12">
     Novos recursos
    </h4>
    <ul>
     <li>
      <strong>
       Console do Google Cloud Platform
      </strong>
      <ul>
       <li>
        Compatibilidade incluída para adição, edição e remoção de
        <a href="https://cloud.google.com/dataproc/docs/concepts/preemptible-vms?hl=pt_br" title="instâncias preemptivas">
         instâncias preemptivas
        </a>
        nos clusters.
       </li>
      </ul>
     </li>
    </ul>
    <h2 data-text="15 de outubro de 2015" id="october_15_2015">
     15 de outubro de 2015
    </h2>
    <h4 data-text="Correções de bugs**" id="bugfixes">
     Correções de bugs**
    </h4>
    <ul>
     <li>
      Correção de um bug em que havia falha no DataNodes ao se registrar no NameNode durante a inicialização, resultando em capacidade do HDFS menor do que a esperada.
     </li>
     <li>
      Impedimento do envio de jobs no estado
      <code>
       Error
      </code>
      .
     </li>
     <li>
      Bug corrigido que impedia a exclusão correta dos clusters em algumas situações.
     </li>
     <li>
      Redução dos erros HTTP
      <code>
       500
      </code>
      ao implantar clusters do Cloud Dataproc.
     </li>
     <li>
      Correção de erros
      <code>
       distcp
      </code>
      de falta de memória com melhor configuração do cluster.
     </li>
     <li>
      Correção da situação em que havia falha na exclusão correta dos jobs e eles ficavam paralisados no estado
      <code>
       Deleting
      </code>
      .
     </li>
    </ul>
    <h4 data-text="Principais melhorias nos serviços" id="core_service_improvements_2">
     Principais melhorias nos serviços
    </h4>
    <ul>
     <li>
      Fornecimento de mais detalhes sobre erros HTTP
      <code>
       500
      </code>
      em vez de mostrar
      <code>
       4xx
errors.
      </code>
     </li>
     <li>
      Adição das informações sobre os recursos existentes para os erros
      <code>
       Resource already exists
      </code>
      .
     </li>
     <li>
      Agora, informações específicas são fornecidas no lugar da mensagem de erro genérica referente aos erros relacionados ao
      <a href="https://cloud.google.com/storage?hl=pt_br" title="Cloud Storage">
       Cloud Storage
      </a>
      .
     </li>
     <li>
      As operações de listagem agora permitem paginação.
     </li>
    </ul>
    <h4 data-text="Otimizações" id="optimizations_2">
     Otimizações
    </h4>
    <ul>
     <li>
      Melhoria significativa na utilização do YARN para jobs MapReduce executados diretamente no
      <a href="https://cloud.google.com/storage?hl=pt_br" title="Cloud Storage">
       Cloud Storage
      </a>
      .
     </li>
     <li>
      Ajustes em
      <code>
       yarn.scheduler.capacity.maximum-am-resource-percent
      </code>
      para possibilitar melhor utilização e compatibilidade com jobs simultâneos.
     </li>
    </ul>
   </section>
  </div>
 </article>
</article>