<article class="devsite-article">
 <article class="devsite-article-inner">
  <h1 class="devsite-page-title">
   Release Notes
  </h1>
  <devsite-toc class="devsite-nav" devsite-toc-embedded="">
  </devsite-toc>
  <div class="devsite-article-body clearfix">
   <section class="intro">
    This page documents production updates to Migrate for Compute Engine. You can
periodically check this page for announcements about new or updated features,
bug fixes, known issues, and deprecated functionality.
   </section>
   <section>
    <p>
     You can see the latest product updates for all of Google Cloud on the
     <a href="/release-notes">
      Google Cloud release notes
     </a>
     page.
    </p>
   </section>
   <section class="xml">
    <p>
     To get the latest product updates delivered to you, add the URL of this page to your
     <a class="external" href="https://wikipedia.org/wiki/Comparison_of_feed_aggregators">
      feed
          reader
     </a>
     , or add the feed URL directly:
     <code dir="ltr" translate="no">
      https://cloud.google.com/feeds/migrate-for-compute-engine-release-notes.xml
     </code>
    </p>
   </section>
   <section class="releases">
    <p>
     For a list of builds for this release and others, see the
     <a href="/migrate/compute-engine/docs/build-history">
      Build history
     </a>
     .
    </p>
    <h2 data-text="Requirements and OS Support" id="requirements_and_os_support" tabindex="0">
     Requirements and OS Support
    </h2>
    <p>
     See
     <a href="/migrate/compute-engine/docs/4.10/concepts/requirements">
      Requirements
     </a>
     and
     <a href="/migrate/compute-engine/docs/4.10/reference/supported-os-versions">
      Supported operating systems
     </a>
     .
    </p>
    <h2 data-text="4.10 new features" id="410_new_features" tabindex="0">
     4.10 new features
    </h2>
    <h3 data-text="Cloud Console integration" id="cloud_console_integration" tabindex="0">
     Cloud Console integration
    </h3>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      V4.10 integrates with the
      <a href="https://cloud.google.com/cloud-console/">
       GCP Console
      </a>
      to allow seamless deployment of the migration manager along with creation of required service accounts.
     </p>
    </div>
    <h3 data-text="Deployment into private access environment" id="deployment_into_private_access_environment" tabindex="0">
     Deployment into private access environment
    </h3>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      V4.10 introduces support for deployment into environments with API private access enabled. In these environments the system will be deployed without public IP and will rely on private access to access cloud APIs. See
      <a href="/migrate/compute-engine/docs/4.10/how-to/configure-manager/configuring-migration-manager">
       Configuring the migration manager
      </a>
      .
     </p>
    </div>
    <h3 data-text="Optional deployment of vCenter plugin" id="optional_deployment_of_vcenter_plugin" tabindex="0">
     Optional deployment of vCenter plugin
    </h3>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      V4.10 introduces the option to deploy into an on-prem source vCenter environment with or without deploying the vCenter plugin. Deploying without vCenter plugin allows you to connect multiple Migrate systems to the same vCenter environment. See
      <a href="/migrate/compute-engine/docs/4.10/how-to/configure-manager/configuring-vms-vm#register_the_vmware_vcenter_environment">
       Registering the VMware vCenter environment
      </a>
      .
     </p>
    </div>
    <h3 data-text="Support pre/post custom script when upgrading windows 2008 to 2012" id="support_prepost_custom_script_when_upgrading_windows_2008_to_2012" tabindex="0">
     Support pre/post custom script when upgrading windows 2008 to 2012
    </h3>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      V4.10 introduces support for running pre/post custom scripts when using the Windows upgrade. You can add custom scripts to the VM. See
      <a href="/migrate/compute-engine/docs/4.10/how-to/upgrading-vms/upgrading-windows-vms">
       Upgrading Windows Server VMs
      </a>
      for more.
     </p>
    </div>
    <h3 data-text="Support migrating Azure Gen2 instances to Compute Engine" id="support_migrating_azure_gen2_instances_to" tabindex="0">
     Support migrating Azure Gen2 instances to Compute Engine
    </h3>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      V4.10 introduces support for migration from
      <a href="/migrate/compute-engine/docs/4.10/reference/supported-os-versions">
       Azure Gen2
      </a>
      instance to Compute Engine instance with UEFI support.
     </p>
    </div>
    <h3 data-text="Automatic O/S discovery and license assignment" id="automatic_os_discovery_and_license_assignment" tabindex="0">
     Automatic O/S discovery and license assignment
    </h3>
    <div class="release-feature">
     <strong>
      FEATURE:
     </strong>
     <p>
      V4.10 introduces automatic identification of migrated OS which will, by default, assign the correct license to the migrated VM. In scenarios where you wish to migrate VMs using Windows BYOL license or Linux premium license you will need to provide these as inputs in the Runbook.
Please see the
      <a href="/migrate/compute-engine/docs/4.10/reference/runbooks">
       licensing section
      </a>
      in the documentation.
     </p>
    </div>
    <h2 data-text="4.10.1" id="4101" tabindex="0">
     4.10.1
    </h2>
    <h3 data-text="Fixed issues" id="fixed_issues" tabindex="0">
     Fixed issues
    </h3>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <p>
      Fixed an issue with Windows partition detection for certain volume structures.
     </p>
    </div>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <p>
      Support added for Azure disks over 4 TB.
     </p>
    </div>
    <h2 data-text="4.10" id="410" tabindex="0">
     4.10
    </h2>
    <h3 data-text="Fixed issues" id="fixed_issues_2" tabindex="0">
     Fixed issues
    </h3>
    <div class="release-fixed">
     <strong>
      FIXED:
     </strong>
     <p>
      Fixed an issue with AWS ena drivers causing Windows images to crash after migration.
     </p>
    </div>
    <h2 data-text="4.10" id="410_2" tabindex="0">
     4.10
    </h2>
    <h3 data-text="Known Issues" id="known_issues" tabindex="0">
     Known Issues
    </h3>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #160405343:
       </strong>
       Due to a
       <a href="https://www.suse.com/support/kb/doc/?id=000019633">
        change in behavior
       </a>
       on the activation flow
    for SUSE, configuring repositories on SUSE Enterprise Linux instances post-detach now fail.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       The following workaround can be used prior
    to detach (either before migration or before detach).
      </p>
      <ol>
       <li>
        Follow the instructions described for Situation 4 at
        <a href="https://www.suse.com/support/kb/doc/?id=000019633">
         https://www.suse.com/support/kb/doc/?id=000019633
        </a>
        to download the required packages for Compute Engine as a tar.gz file.
       </li>
       <li>
        <p>
         <strong>
          For SLES 12.x
         </strong>
         , then run the following commands:
        </p>
        <pre class="devsite-terminal" dir="ltr" suppresswarning="true" translate="no">sha1sum late_instance_offline_update_gce_SLE12.tar.gz
<code class="devsite-terminal" dir="ltr" translate="no">tar -xf late_instance_offline_update_gce_SLE12.tar.gz</code>
<code class="devsite-terminal" dir="ltr" translate="no">cd x86_64/</code>
<code class="devsite-terminal" dir="ltr" translate="no">zypper --no-refresh --no-remote --non-interactive in *.rpm</code></pre>
       </li>
       <li>
        <p>
         <strong>
          For SLES 15.x
         </strong>
         , then run the following commands:
        </p>
        <pre class="devsite-terminal" dir="ltr" suppresswarning="true" translate="no">sha1sum late_instance_offline_update_gce_SLE15.tar.gz
<code class="devsite-terminal" dir="ltr" translate="no">tar -xf late_instance_offline_update_gce_SLE15.tar.gz</code>
<code class="devsite-terminal" dir="ltr" translate="no">cd x86_64/</code>
<code class="devsite-terminal" dir="ltr" translate="no">zypper --no-refresh --no-remote --non-interactive in *.rpm</code></pre>
       </li>
      </ol>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #149004085:
       </strong>
       Ubuntu 14 from on-premise may fail to start
      networking post detach.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Connect via the serial console and manually
      add the network interface with DHCP.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #145086776:
       </strong>
       In rare cases, older versions of RHEL7 may
      hang during streaming or reach a Kernel panic. This issues were resolved in later versions of RHEL7.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Run
       <code dir="ltr" translate="no">
        sudo yum update
       </code>
       before
      migrating to update the system.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #145644737:
       </strong>
       Clones created on Azure or AWS from
      instances of Linux distributions that use cloud-init may experience issues
      in booting after installing the Linux prep package.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Uninstall the package before cloning and
      reinstall when preparing to migrate.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #143313211:
       </strong>
       Customer migrating RHEL 6.8 VM may
      experience boot issues in the cloud destination.
      </p>
      <p>
       RHEL 6.x systems using kernel versions 2.6.32-xxx and using LVM may reach
      a kernel panic when booting in Compute Engine during migration.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       The kernel should be upgraded to 2.6.32-754
      or higher before migrating.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #143262721:
       </strong>
       Migration of VM from Azure fails when data
      disk is greater than 4 terabytes.
      </p>
      <p>
       At this time, Migrate for Compute Engine does not support migration of Azure
      VMs with data disks bigger than 4TB.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Make sure VM has data disk smaller than 4TB.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131532690:
       </strong>
       Run-in-cloud and migration operations may
      fail for Windows Server 2016 workload when Symantec Endpoint Protection
      (SEP) is installed. This may also happen when SEP appears to be disabled.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Modify workload Network interface bindings
      to remove the SEP option.
      </p>
      <ol>
       <li>
        Download
        <a href="https://gallery.technet.microsoft.com/Hyper-V-Network-VSP-Bind-cf937850">
         Microsoft
        Network VSP Bind (nvspbind)
        </a>
       </li>
       <li>
        Install Microsoft_Nvspbind_package.EXE into c:\temp.
       </li>
       <li>
        Open a command prompt as an Administrator and run the following:
        <pre dir="ltr" translate="no">nvspbind.exe /d * symc_teefer2</pre>
       </li>
      </ol>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131614405:
       </strong>
       When the Velostrata Prep RPM is installed 
      on SUSE Linux Enterprise Server 11, the VM obtains a DHCP IP address in
      addition to an existing static IP configuration. This issue occurs when
      the VM is started on-premises in a subnet that is enabled with DHCP
      services.
      </p>
      <p>
       Note: The issue does not occur when the subnet has no DHCP services.
      There is no connectivity impact for communications with the original
      static IP address.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131637800:
       </strong>
       After registering the Velostrata plug-in, 
      running the Cloud Extension wizard might generate an error "XXXXXXXXXX"
      upon "Finish".
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Un-register the Velostrata plug-in and 
      restart the vSphere Web client service, then re-register the plug-in.
      Contact support if the issue persists.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131548730:
       </strong>
       In some cases, when a VM is moved to 
      Run-in-Cloud while a 3rd party VM-level backup solution holds a temporary
      snapshot, the Migrate for Compute Engine periodic write-back operations will
      not complete even after the backup solution deletes the temporary snapshot.
      The uncommitted writes counter on the VM will show an increasing size and
      no consistency checkpoint will be created on-premises.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Select the Run On-Premises action for the VM
      and wait for the task to complete, which will commit all pending writes.
      Then select the Run-in-Cloud action again. Note that committing many
      pending writes may take a while. Do not use the Force option as this will
      result in the loss of the uncommitted writes.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131605387:
       </strong>
       vCenter reboot causes Velostrata
      tasks in vCenter to disappear from UI. This is a vCenter limitation.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Use the Velostrata PowerShell module to 
      monitor Velostrata managed VMs or Cloud Extensions tasks that are
      currently running.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131638716:
       </strong>
       With an ESXi host in maintenance mode, if a
      VM is moved to cloud, the operation will fail and get stuck in the
      rollback phase.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Manually cancel the Run-in-Cloud task,
      migrate the VM to another ESXi host in the cluster and retry the
      Run-in-Cloud operation.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131638455:
       </strong>
       A Run-in-Cloud operation fails with the
      error - "Failed to create virtual machine snapshot. The attempted
      operation cannot be performed in the current state (Powered off)".
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       The VMware VM snapshot file may be pointing
      to a non-existent snapshot. Contact support for assistance in correcting
      the issue.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131534862:
       </strong>
       In rare cases, after running a Workload
      back on-premises - Workload VMDK's are locked. In certain cases, this is
      due to network disruptions between the Velostrata
      management appliance and the ESXi host on which the workload is running.
      </p>
      <p>
       Note: The issue will resolve itself after 1-2 hours.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131550214:
       </strong>
       During Detach, the operation might fail
      with the following error message: "Operation was canceled".
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Retry the Detach operation.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131650367:
       </strong>
       When performing a detach after a cancel
      detach operation, the action may fail.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Retry the operation.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131649978:
       </strong>
       In the event of certain system failures,
      Velostrata components disconnect from vCenter. In this case, an 
      event may not be sent, resulting in the alarm either not being set properly
      or not being cleared properly.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Clear the alarm manually in vCenter.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131532549:
       </strong>
       For workloads with a Windows machine using a
      retail license, when returning from the cloud, the license is not present.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Reinstall the license.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131555885:
       </strong>
       vCenter "Export OVA" operation is available
      when the VM in cloud is running in cache mode, however, this operation
      results in a corrupted OVA.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Only create OVA after the detach.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131647857:
       </strong>
       In rare cases, when a cloud component
      instance is created and system fails before it is tagged, the instance
      will remain untagged. This will not allow full clean-up or repair of the
      CE.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Manually tag the instance, and then run
      "Repair".
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131537125:
       </strong>
       Cloud Extension high availability does not
      work for workloads running Ubuntu OS with LVM configuration.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Update the kernel to 3.13.0-161 or higher.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131560126:
       </strong>
       Suse12: Due to a bug in SUSE kernel older
      than 4.2, configurations that include BTRFS mounts with subvolumes are
      not supported.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Upgrade to SUSE version with Kernel &gt;=4.2 (SP2).
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131533480:
       </strong>
       When using the Create Cloud Extension
      wizard, using an illegal HTTP proxy address will not generate a warning
      message.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Delete the CE and then create the CE with
      a valid HTTP proxy address.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131647654:
       </strong>
       Run on-premises operation succeeded but
      the status is marked as failed with error "Failed to consolidate snapshots"
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Consolidate snapshots via vCenter, and
      clear the error manually.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131558198:
       </strong>
       PowerShell client for cloud to cloud Runbook
      reports errors when running on PowerShell 3.0
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Upgrade to PowerShell 4.0
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131533056:
       </strong>
       When migrating RHEL 7.4 from AWS to
      Google Cloud, Google Cloud agent will not be installed
      automatically.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Manually remove the AWS agent and install
      Google Cloud agent
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131532713:
       </strong>
       After Offline Migration of Windows 2003R2,
      if a NIC is manually deleted, it may be impossible to auto-detect and
      automatically reinstall it.
      </p>
      <p>
       Workaround: The VM storage can be attached to a different VM, and the NIC
      Registry entry could be imported manually using a similar VM as a
      reference. Contact support for assistance.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131532666:
       </strong>
       Linux versions running with kernel version
      2.6.32 may experience a kernel panic on ephemeral storage access failures;
      these are more likely while streaming over iSCSI.
      </p>
      <p>
       Workaround: Upgrade your kernel. The issue will also reduce in likelihood
      after Detach.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131532846:
       </strong>
       Certain firewalls and anti-viruses may
      cause Windows VMs to fail when moved to cloud by blocking iSCSI traffic.
      </p>
      <p>
       Workaround: Disable the affecting service while migrating and reinstall
      after Detach.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #131532882:
       </strong>
       In certain cases, initiating Run in Cloud
      during a Windows update may cause the update to terminate abruptly and
      cause a failure to boot in the cloud.
      </p>
      <p>
       Workaround: Allow the system to finish Windows update and/or suspend
      Windows updates before migrating.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #135664281:
       </strong>
       When completing or canceling Azure to Google Cloud
      migration, if Velostrata Management failed to start the importer, 
      Velostrata-created resources may be left in the original instance's
      resource group.
      </p>
     </div>
    </p>
    <p>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #133137658:
       </strong>
       Scenario: No network connection between
      Migration Manager and VSphere
      </p>
      <p>
       Customer Impact: RunInCloud task will stay stuck due to failure in call to
    getReadSessions on VSphere.
      </p>
      <p>
       <strong>
        Workaround
       </strong>
       : Fix the network connection. If not, cancel
    the task and try again.
      </p>
     </div>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #135573857
       </strong>
       Scenario: When moving a VM back on-prem with
      "force" flag, failure to consolidate snapshot will cause the VM to remain
      as managed by Velostrata. RunInCloud on the same VM may fail
      since it is not allowed on managed VMs.
      </p>
      <p>
       <strong>
        Workaround:
       </strong>
       Wait a couple of minutes and try again.
      </p>
     </div>
     <div class="release-issue">
      <strong>
       ISSUE:
      </strong>
      <p>
       <strong>
        #137082702:
       </strong>
       In rare cases, the Cancel detach operation
        succeeds but the VM instance will fail to start.
      </p>
      <p>
       <strong>
        Workaround
       </strong>
       : Move the instance back and move it again to
      the cloud.
      </p>
     </div>
    </p>
   </section>
  </div>
 </article>
</article>