<article class="devsite-article">
 <article class="devsite-article-inner">
  <h1 class="devsite-page-title">
   Release notes: Cloud Dataflow SDK for Python
  </h1>
  <devsite-toc class="devsite-nav" devsite-toc-embedded="">
  </devsite-toc>
  <div class="devsite-article-body clearfix">
   <section class="intro">
    <p class="note">
     <b>
      NOTE:
     </b>
     The
     <a href="https://beam.apache.org/get-started/downloads/#releases">
      Apache Beam
  downloads
     </a>
     page contains release notes for the Apache Beam SDK releases.
    </p>
    <p>
     <aside class="caution">
      <p>
       <strong>
        SDK Decommission Notice:
       </strong>
       The following SDK versions will
  be decommissioned in late 2019 due to the
       <a href="https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html">
        discontinuation
    of support for JSON-RPC and Global HTTP Batch Endpoints
       </a>
       .
      </p>
      <ul>
       <li>
        Apache Beam SDK for Java, versions 2.0.0 to 2.4.0 (inclusive)
       </li>
       <li>
        Apache Beam SDK for Python, versions 2.0.0 to 2.4.0 (inclusive)
       </li>
       <li>
        Dataflow SDK for Java, versions 2.0.0 to 2.4.0 (inclusive)
       </li>
       <li>
        Dataflow SDK for Python, 2.0.0 to 2.4.0 (inclusive)
       </li>
      </ul>
      <p>
       Previously, the date planned for this decommissioning was March 25, 2019, but in response to
  customer requests, we are extending this timeline. The new end date has yet to be finalized but is
  expected to happen in 2019. When decommissioning happens, you will no longer be able to submit new
  Dataflow jobs or update running Dataflow jobs that use the
  decommissioned SDKs. In addition, existing streaming jobs that use these SDK versions may fail.
      </p>
     </aside>
    </p>
    <p>
     <aside class="caution">
      <p>
       <strong>
        Dataflow SDK Deprecation Notice:
       </strong>
       The
  Dataflow SDK 2.5.0 is the last Dataflow SDK
  release that is separate from the Apache Beam SDK releases. The
  Dataflow service supports official Apache Beam SDK
  releases as documented in the
       <a href="/dataflow/docs/support/sdk-version-support-status">
        SDK version support status page
       </a>
       .
      </p>
     </aside>
    </p>
    <p>
     This page documents production updates to the Dataflow SDK for Python. You can
periodically check this page for announcements about new or updated features,
bug fixes, known issues, and deprecated functionality.
    </p>
    <p class="note">
     The Dataflow SDK for Python now supports streaming execution (beta),
as of Dataflow SDK 2.5.0.
    </p>
    <p>
     The
     <a href="/dataflow/docs/support/sdk-version-support-status">
      SDK version support status page
     </a>
     contains
information about the support status of each release of the Dataflow SDK.
    </p>
    <p>
     To install and use the Dataflow SDK, see the
     <a href="/dataflow/docs/installing-dataflow-sdk">
      Dataflow SDK installation guide
     </a>
     .
    </p>
   </section>
   <section class="xml">
   </section>
   <section class="releases">
    <h2 data-text="Cloud Dataflow SDK distribution contents" id="dataflow-sdk-contents">
     Cloud Dataflow SDK distribution contents
    </h2>
    <p>
     The Dataflow SDK distribution contains a subset of the Apache Beam ecosystem.
This subset includes the necessary components to define your pipeline and execute it
locally and on the Dataflow service, such as:
     <ul>
      <li>
       The core SDK
      </li>
      <li>
       DirectRunner and DataflowRunner
      </li>
      <li>
       I/O components for other Google Cloud services
      </li>
     </ul>
    </p>
    <p>
     The Dataflow SDK distribution
     <b>
      does not
     </b>
     include other Beam components, such as:
     <ul>
      <li>
       Runners for other distributed processing engines
      </li>
      <li>
       I/O components for non-Google Cloud services
      </li>
     </ul>
    </p>
    <h2 data-text="Release notes" id="release_notes">
     Release notes
    </h2>
    <p>
     This section provides each version's most relevant changes for Dataflow
customers.
    </p>
    <h3 data-text="March 24, 2019" id="march_24_2019">
     March 24, 2019
    </h3>
    <div class="release-changed">
     <strong>
      CHANGED:
     </strong>
     <p>
      The following SDK versions will be decommissioned later in 2019 due to the
      <a href="https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html">
       discontinuation
    of support for JSON-RPC and Global HTTP Batch Endpoints
      </a>
      . Note that this
    change overrides the release note from December 17, 2018, that states that
    decommissioning was expected to happen in March 2019.
     </p>
     <ul>
      <li>
       Apache Beam SDK for Java, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
      <li>
       Apache Beam SDK for Python, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
      <li>
       Dataflow SDK for Java, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
      <li>
       Dataflow SDK for Python, 2.0.0 to 2.4.0 (inclusive)
      </li>
     </ul>
     <p>
      See the
      <a href="/dataflow/docs/support/sdk-version-support-status">
       SDK
version support status page
      </a>
      for detailed SDK support status.
     </p>
    </div>
    <h3 data-text="December 17, 2018" id="december_17_2018">
     December 17, 2018
    </h3>
    <div class="release-deprecated">
     <strong>
      DEPRECATED:
     </strong>
     <p>
      The following SDK versions will be
decommissioned on March 25, 2019 due to the
      <a href="https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html">
       discontinuation
  of support for JSON-RPC and Global HTTP Batch Endpoints
      </a>
      .
Shortly after this date, you will no longer be able to submit new
Dataflow jobs or update running Dataflow jobs that
use the decommissioned SDKs. In addition, existing streaming jobs that use
these SDK versions might fail.
     </p>
     <ul>
      <li>
       Apache Beam SDK for Java, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
      <li>
       Apache Beam SDK for Python, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
      <li>
       Dataflow SDK for Java, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
      <li>
       Dataflow SDK for Python, versions 2.0.0 to 2.4.0 (inclusive)
      </li>
     </ul>
    </div>
   </section>
  </div>
 </article>
</article>